{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9705a695-f937-4929-b6cf-90949390625f",
   "metadata": {},
   "source": [
    "# <center>Project of Machine Learning</center>\n",
    "\n",
    "<center>\n",
    "Master in Data Science and Advanced Analytics <br>\n",
    "NOVA Information Management School\n",
    "</center>\n",
    "\n",
    "** **\n",
    "## <center>*TO GRANT OR NOT TO GRANT: DECIDING ON COMPENSATION BENEFITS*</center>\n",
    "\n",
    "<center>\n",
    "Group 17 <br>\n",
    "Diogo Ruivo, 20240584  <br>\n",
    "Jos√© Tiago, 20240582  <br>\n",
    "Matilde Miguel, 20240549  <br>\n",
    "Nuno Sousa, 20222125  <br>\n",
    "Rafael Lopes, 20240588  <br>\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "</center>\n",
    "\n",
    "\n",
    "** **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11534c04-0cc2-4ce9-9a7d-e5b4523277e0",
   "metadata": {},
   "source": [
    "## Project Description     \n",
    "This project addresses the task of automating decisions on compensation in insurance claims related to workplace injuries. Using historical data from the New York WCB, our objective is to predict the type of compensation a claim will be awarded, thereby optimizing the decision-making process and improving consistency in outcomes.   \n",
    "\n",
    "This project aims to build a robust predictive model to classify injury claims in a multiclass classification scenario, explore and optimize model performance through preprocessing techniques and hyperparameter tuning and provide interpretative analysis to identify the most influential variables in the final decision.   \n",
    "\n",
    "Prior studies show that machine learning techniques, such as random forests and XGBoost, have proven effective in automating decision-making processes in insurance. Our work builds on these approaches, exploring multiple variables related to demographics and injury types to create an interpretable and reliable decision-making model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c890b7f-54e1-4939-99ce-50acd3aa0e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data manipulation and analysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "import missingno as msno\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "\n",
    "# Feature engineering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import statistics\n",
    "\n",
    "# Feature selection\n",
    "from scipy.stats import chi2_contingency, spearmanr\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Scaling and encoding\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder, OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "# Modeling\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report, roc_auc_score, roc_curve, auc, precision_score, recall_score\n",
    "\n",
    "# Resampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, LeaveOneOut, cross_val_score, StratifiedKFold\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203fdfde-201c-4984-9e97-7e1cd25c9a8e",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"importdataset\">\n",
    "    \n",
    "# 2. Import Dataset\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eebe2b2-3a1e-4c3d-8ee4-6cc90b9e8ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_data.csv')\n",
    "test = pd.read_csv('test_data.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "%store -r Agreement_Reached\n",
    "test['Agreement Reached'] = Agreement_Reached #adding the variable to the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bbb8ae1-344e-4714-873c-0b60d4a920a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = test.columns.tolist()\n",
    "cols[-2], cols[-1] = cols[-1], cols[-2]\n",
    "test = test[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7e0c8c-5259-48a4-ad72-a55c1bca0943",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"initialanalysis\">\n",
    "    \n",
    "# 3. Initial Analysis\n",
    "    \n",
    "</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "841c55c1-8b21-4f9a-ae21-ceda67811476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accident Date</th>\n",
       "      <th>Age at Injury</th>\n",
       "      <th>Alternative Dispute Resolution</th>\n",
       "      <th>Assembly Date</th>\n",
       "      <th>Attorney/Representative</th>\n",
       "      <th>Average Weekly Wage</th>\n",
       "      <th>Birth Year</th>\n",
       "      <th>C-2 Date</th>\n",
       "      <th>C-3 Date</th>\n",
       "      <th>Carrier Name</th>\n",
       "      <th>...</th>\n",
       "      <th>WCIO Cause of Injury Code</th>\n",
       "      <th>WCIO Cause of Injury Description</th>\n",
       "      <th>WCIO Nature of Injury Code</th>\n",
       "      <th>WCIO Nature of Injury Description</th>\n",
       "      <th>WCIO Part Of Body Code</th>\n",
       "      <th>WCIO Part Of Body Description</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Agreement Reached</th>\n",
       "      <th>WCB Decision</th>\n",
       "      <th>Number of Dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>31.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW HAMPSHIRE INSURANCE CO</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>FROM LIQUID OR GREASE SPILLS</td>\n",
       "      <td>10.0</td>\n",
       "      <td>CONTUSION</td>\n",
       "      <td>62.0</td>\n",
       "      <td>BUTTOCKS</td>\n",
       "      <td>13662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Work Related</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>46.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Y</td>\n",
       "      <td>1745.93</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>ZURICH AMERICAN INSURANCE CO</td>\n",
       "      <td>...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>REPETITIVE MOTION</td>\n",
       "      <td>49.0</td>\n",
       "      <td>SPRAIN OR TEAR</td>\n",
       "      <td>38.0</td>\n",
       "      <td>SHOULDER(S)</td>\n",
       "      <td>14569</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not Work Related</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-06</td>\n",
       "      <td>40.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>N</td>\n",
       "      <td>1434.80</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INDEMNITY INSURANCE CO OF</td>\n",
       "      <td>...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>OBJECT BEING LIFTED OR HANDLED</td>\n",
       "      <td>7.0</td>\n",
       "      <td>CONCUSSION</td>\n",
       "      <td>10.0</td>\n",
       "      <td>MULTIPLE HEAD INJURY</td>\n",
       "      <td>12589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Work Related</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>61.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STATE INSURANCE FUND</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>HAND TOOL, UTENSIL; NOT POWERED</td>\n",
       "      <td>43.0</td>\n",
       "      <td>PUNCTURE</td>\n",
       "      <td>36.0</td>\n",
       "      <td>FINGER(S)</td>\n",
       "      <td>12603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Work Related</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>67.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INDEMNITY INS. OF N AMERICA</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>FALL, SLIP OR TRIP, NOC</td>\n",
       "      <td>10.0</td>\n",
       "      <td>CONTUSION</td>\n",
       "      <td>38.0</td>\n",
       "      <td>SHOULDER(S)</td>\n",
       "      <td>11772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Work Related</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>48.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LM INSURANCE CORP</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>CUT, PUNCTURE, SCRAPE, NOC</td>\n",
       "      <td>40.0</td>\n",
       "      <td>LACERATION</td>\n",
       "      <td>36.0</td>\n",
       "      <td>FINGER(S)</td>\n",
       "      <td>13029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Work Related</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>33.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>STATE INSURANCE FUND</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>OTHER - MISCELLANEOUS, NOC</td>\n",
       "      <td>71.0</td>\n",
       "      <td>ALL OTHER OCCUPATIONAL DISEASE INJURY, NOC</td>\n",
       "      <td>38.0</td>\n",
       "      <td>SHOULDER(S)</td>\n",
       "      <td>10305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Work Related</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>55.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROCHESTER, UNIVERSITY OF</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>OTHER - MISCELLANEOUS, NOC</td>\n",
       "      <td>59.0</td>\n",
       "      <td>ALL OTHER SPECIFIC INJURIES, NOC</td>\n",
       "      <td>60.0</td>\n",
       "      <td>LUNGS</td>\n",
       "      <td>14620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Work Related</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>20.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>N</td>\n",
       "      <td>225.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LM INSURANCE CORP</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>STRUCK OR INJURED, NOC</td>\n",
       "      <td>59.0</td>\n",
       "      <td>ALL OTHER SPECIFIC INJURIES, NOC</td>\n",
       "      <td>14.0</td>\n",
       "      <td>EYE(S)</td>\n",
       "      <td>11231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Work Related</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Accident Date  Age at Injury Alternative Dispute Resolution Assembly Date  \\\n",
       "0    2019-12-30           31.0                              N    2020-01-01   \n",
       "1    2019-08-30           46.0                              N    2020-01-01   \n",
       "2    2019-12-06           40.0                              N    2020-01-01   \n",
       "3           NaN            NaN                            NaN    2020-01-01   \n",
       "4    2019-12-30           61.0                              N    2020-01-01   \n",
       "5    2019-12-26           67.0                              N    2020-01-01   \n",
       "6    2019-12-28           48.0                              N    2020-01-01   \n",
       "7    2019-12-30           33.0                              N    2020-01-01   \n",
       "8    2019-12-23           55.0                              N    2020-01-01   \n",
       "9    2019-12-29           20.0                              N    2020-01-01   \n",
       "\n",
       "  Attorney/Representative  Average Weekly Wage  Birth Year    C-2 Date  \\\n",
       "0                       N                 0.00      1988.0  2019-12-31   \n",
       "1                       Y              1745.93      1973.0  2020-01-01   \n",
       "2                       N              1434.80      1979.0  2020-01-01   \n",
       "3                     NaN                  NaN         NaN         NaN   \n",
       "4                       N                  NaN      1958.0  2019-12-31   \n",
       "5                       N                 0.00      1952.0  2019-12-31   \n",
       "6                       N                 0.00      1971.0  2019-12-31   \n",
       "7                       N                 0.00      1986.0  2019-12-31   \n",
       "8                       N                 0.00      1964.0  2020-01-01   \n",
       "9                       N               225.00         NaN  2019-12-31   \n",
       "\n",
       "     C-3 Date                  Carrier Name  ... WCIO Cause of Injury Code  \\\n",
       "0         NaN    NEW HAMPSHIRE INSURANCE CO  ...                      27.0   \n",
       "1  2020-01-14  ZURICH AMERICAN INSURANCE CO  ...                      97.0   \n",
       "2         NaN     INDEMNITY INSURANCE CO OF  ...                      79.0   \n",
       "3         NaN                           NaN  ...                       NaN   \n",
       "4         NaN          STATE INSURANCE FUND  ...                      16.0   \n",
       "5         NaN   INDEMNITY INS. OF N AMERICA  ...                      31.0   \n",
       "6         NaN             LM INSURANCE CORP  ...                      19.0   \n",
       "7  2020-03-04          STATE INSURANCE FUND  ...                      99.0   \n",
       "8         NaN      ROCHESTER, UNIVERSITY OF  ...                      99.0   \n",
       "9         NaN             LM INSURANCE CORP  ...                      81.0   \n",
       "\n",
       "   WCIO Cause of Injury Description WCIO Nature of Injury Code  \\\n",
       "0      FROM LIQUID OR GREASE SPILLS                       10.0   \n",
       "1                 REPETITIVE MOTION                       49.0   \n",
       "2    OBJECT BEING LIFTED OR HANDLED                        7.0   \n",
       "3                               NaN                        NaN   \n",
       "4   HAND TOOL, UTENSIL; NOT POWERED                       43.0   \n",
       "5           FALL, SLIP OR TRIP, NOC                       10.0   \n",
       "6        CUT, PUNCTURE, SCRAPE, NOC                       40.0   \n",
       "7        OTHER - MISCELLANEOUS, NOC                       71.0   \n",
       "8        OTHER - MISCELLANEOUS, NOC                       59.0   \n",
       "9            STRUCK OR INJURED, NOC                       59.0   \n",
       "\n",
       "            WCIO Nature of Injury Description WCIO Part Of Body Code  \\\n",
       "0                                   CONTUSION                   62.0   \n",
       "1                              SPRAIN OR TEAR                   38.0   \n",
       "2                                  CONCUSSION                   10.0   \n",
       "3                                         NaN                    NaN   \n",
       "4                                    PUNCTURE                   36.0   \n",
       "5                                   CONTUSION                   38.0   \n",
       "6                                  LACERATION                   36.0   \n",
       "7  ALL OTHER OCCUPATIONAL DISEASE INJURY, NOC                   38.0   \n",
       "8            ALL OTHER SPECIFIC INJURIES, NOC                   60.0   \n",
       "9            ALL OTHER SPECIFIC INJURIES, NOC                   14.0   \n",
       "\n",
       "  WCIO Part Of Body Description Zip Code Agreement Reached      WCB Decision  \\\n",
       "0                      BUTTOCKS    13662               0.0  Not Work Related   \n",
       "1                   SHOULDER(S)    14569               1.0  Not Work Related   \n",
       "2          MULTIPLE HEAD INJURY    12589               0.0  Not Work Related   \n",
       "3                           NaN      NaN               NaN               NaN   \n",
       "4                     FINGER(S)    12603               0.0  Not Work Related   \n",
       "5                   SHOULDER(S)    11772               0.0  Not Work Related   \n",
       "6                     FINGER(S)    13029               0.0  Not Work Related   \n",
       "7                   SHOULDER(S)    10305               0.0  Not Work Related   \n",
       "8                         LUNGS    14620               0.0  Not Work Related   \n",
       "9                        EYE(S)    11231               0.0  Not Work Related   \n",
       "\n",
       "   Number of Dependents  \n",
       "0                   1.0  \n",
       "1                   4.0  \n",
       "2                   6.0  \n",
       "3                   NaN  \n",
       "4                   1.0  \n",
       "5                   5.0  \n",
       "6                   1.0  \n",
       "7                   6.0  \n",
       "8                   6.0  \n",
       "9                   6.0  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "631b21e4-a2b8-42ee-970c-708de9fb838a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accident Date</th>\n",
       "      <th>Age at Injury</th>\n",
       "      <th>Alternative Dispute Resolution</th>\n",
       "      <th>Assembly Date</th>\n",
       "      <th>Attorney/Representative</th>\n",
       "      <th>Average Weekly Wage</th>\n",
       "      <th>Birth Year</th>\n",
       "      <th>C-2 Date</th>\n",
       "      <th>C-3 Date</th>\n",
       "      <th>Carrier Name</th>\n",
       "      <th>...</th>\n",
       "      <th>OIICS Nature of Injury Description</th>\n",
       "      <th>WCIO Cause of Injury Code</th>\n",
       "      <th>WCIO Cause of Injury Description</th>\n",
       "      <th>WCIO Nature of Injury Code</th>\n",
       "      <th>WCIO Nature of Injury Description</th>\n",
       "      <th>WCIO Part Of Body Code</th>\n",
       "      <th>WCIO Part Of Body Description</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Agreement Reached</th>\n",
       "      <th>Number of Dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-24</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INDEMNITY INSURANCE CO OF</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>FALL, SLIP OR TRIP, NOC</td>\n",
       "      <td>10.0</td>\n",
       "      <td>CONTUSION</td>\n",
       "      <td>54.0</td>\n",
       "      <td>LOWER LEG</td>\n",
       "      <td>10466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-20</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A I U INSURANCE COMPANY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>FALLING OR FLYING OBJECT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>CONTUSION</td>\n",
       "      <td>10.0</td>\n",
       "      <td>MULTIPLE HEAD INJURY</td>\n",
       "      <td>11691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>59</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AMGUARD INSURANCE COMPANY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>STATIONARY OBJECT</td>\n",
       "      <td>49.0</td>\n",
       "      <td>SPRAIN OR TEAR</td>\n",
       "      <td>62.0</td>\n",
       "      <td>BUTTOCKS</td>\n",
       "      <td>10604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>55</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INDEMNITY INS. OF N AMERICA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>FROM DIFFERENT LEVEL (ELEVATION)</td>\n",
       "      <td>10.0</td>\n",
       "      <td>CONTUSION</td>\n",
       "      <td>53.0</td>\n",
       "      <td>KNEE</td>\n",
       "      <td>11411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-20</td>\n",
       "      <td>25</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW HAMPSHIRE INSURANCE CO</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0</td>\n",
       "      <td>OBJECT BEING LIFTED OR HANDLED</td>\n",
       "      <td>40.0</td>\n",
       "      <td>LACERATION</td>\n",
       "      <td>37.0</td>\n",
       "      <td>THUMB</td>\n",
       "      <td>11212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>36</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYC TRANSIT AUTHORITY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>OTHER THAN PHYSICAL CAUSE OF INJURY</td>\n",
       "      <td>77.0</td>\n",
       "      <td>MENTAL STRESS</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NO PHYSICAL INJURY</td>\n",
       "      <td>10941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>N</td>\n",
       "      <td>688.20</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WAL-MART ASSOCIATES, INC.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>LIFTING</td>\n",
       "      <td>49.0</td>\n",
       "      <td>SPRAIN OR TEAR</td>\n",
       "      <td>38.0</td>\n",
       "      <td>SHOULDER(S)</td>\n",
       "      <td>14131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-12-13</td>\n",
       "      <td>43</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ERIE INSURANCE CO OF NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>FROM LIQUID OR GREASE SPILLS</td>\n",
       "      <td>49.0</td>\n",
       "      <td>SPRAIN OR TEAR</td>\n",
       "      <td>53.0</td>\n",
       "      <td>KNEE</td>\n",
       "      <td>13357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>40</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STARR INDEMNITY &amp; LIABILITY CO</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.0</td>\n",
       "      <td>FOREIGN MATTER (BODY) IN EYE(S)</td>\n",
       "      <td>25.0</td>\n",
       "      <td>FOREIGN BODY</td>\n",
       "      <td>14.0</td>\n",
       "      <td>EYE(S)</td>\n",
       "      <td>11735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>48</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>Y</td>\n",
       "      <td>1180.74</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>STATE INSURANCE FUND</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>FROM DIFFERENT LEVEL (ELEVATION)</td>\n",
       "      <td>49.0</td>\n",
       "      <td>SPRAIN OR TEAR</td>\n",
       "      <td>38.0</td>\n",
       "      <td>SHOULDER(S)</td>\n",
       "      <td>14720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Accident Date  Age at Injury Alternative Dispute Resolution Assembly Date  \\\n",
       "0    2022-12-24             19                              N    2023-01-02   \n",
       "1    2022-11-20             19                              N    2023-01-02   \n",
       "2    2022-12-26             59                              N    2023-01-02   \n",
       "3    2022-12-28             55                              N    2023-01-02   \n",
       "4    2022-12-20             25                              N    2023-01-02   \n",
       "5    2022-12-28             36                              N    2023-01-02   \n",
       "6    2022-12-22             19                              N    2023-01-02   \n",
       "7    2022-12-13             43                              N    2023-01-02   \n",
       "8    2022-12-28             40                              N    2023-01-02   \n",
       "9    2022-11-01             48                              N    2023-01-02   \n",
       "\n",
       "  Attorney/Representative  Average Weekly Wage  Birth Year    C-2 Date  \\\n",
       "0                       N                  NaN      2003.0  2023-01-02   \n",
       "1                       N                  NaN      2003.0  2023-01-02   \n",
       "2                       N                 0.00      1963.0  2022-12-31   \n",
       "3                       N                 0.00         0.0  2023-01-02   \n",
       "4                       N                 0.00      1997.0  2022-12-31   \n",
       "5                       N                 0.00      1986.0  2023-01-02   \n",
       "6                       N               688.20      2003.0  2022-12-30   \n",
       "7                       N                 0.00         0.0  2023-01-02   \n",
       "8                       N                 0.00      1982.0  2022-12-31   \n",
       "9                       Y              1180.74      1974.0  2023-01-02   \n",
       "\n",
       "     C-3 Date                    Carrier Name  ...  \\\n",
       "0         NaN       INDEMNITY INSURANCE CO OF  ...   \n",
       "1         NaN         A I U INSURANCE COMPANY  ...   \n",
       "2         NaN       AMGUARD INSURANCE COMPANY  ...   \n",
       "3         NaN     INDEMNITY INS. OF N AMERICA  ...   \n",
       "4         NaN      NEW HAMPSHIRE INSURANCE CO  ...   \n",
       "5         NaN           NYC TRANSIT AUTHORITY  ...   \n",
       "6         NaN       WAL-MART ASSOCIATES, INC.  ...   \n",
       "7         NaN         ERIE INSURANCE CO OF NY  ...   \n",
       "8         NaN  STARR INDEMNITY & LIABILITY CO  ...   \n",
       "9  2023-01-09            STATE INSURANCE FUND  ...   \n",
       "\n",
       "  OIICS Nature of Injury Description  WCIO Cause of Injury Code  \\\n",
       "0                                NaN                       31.0   \n",
       "1                                NaN                       75.0   \n",
       "2                                NaN                       68.0   \n",
       "3                                NaN                       25.0   \n",
       "4                                NaN                       79.0   \n",
       "5                                NaN                       90.0   \n",
       "6                                NaN                       56.0   \n",
       "7                                NaN                       27.0   \n",
       "8                                NaN                       87.0   \n",
       "9                                NaN                       25.0   \n",
       "\n",
       "      WCIO Cause of Injury Description WCIO Nature of Injury Code  \\\n",
       "0              FALL, SLIP OR TRIP, NOC                       10.0   \n",
       "1             FALLING OR FLYING OBJECT                       10.0   \n",
       "2                    STATIONARY OBJECT                       49.0   \n",
       "3     FROM DIFFERENT LEVEL (ELEVATION)                       10.0   \n",
       "4       OBJECT BEING LIFTED OR HANDLED                       40.0   \n",
       "5  OTHER THAN PHYSICAL CAUSE OF INJURY                       77.0   \n",
       "6                              LIFTING                       49.0   \n",
       "7         FROM LIQUID OR GREASE SPILLS                       49.0   \n",
       "8      FOREIGN MATTER (BODY) IN EYE(S)                       25.0   \n",
       "9     FROM DIFFERENT LEVEL (ELEVATION)                       49.0   \n",
       "\n",
       "  WCIO Nature of Injury Description WCIO Part Of Body Code  \\\n",
       "0                         CONTUSION                   54.0   \n",
       "1                         CONTUSION                   10.0   \n",
       "2                    SPRAIN OR TEAR                   62.0   \n",
       "3                         CONTUSION                   53.0   \n",
       "4                        LACERATION                   37.0   \n",
       "5                     MENTAL STRESS                   66.0   \n",
       "6                    SPRAIN OR TEAR                   38.0   \n",
       "7                    SPRAIN OR TEAR                   53.0   \n",
       "8                      FOREIGN BODY                   14.0   \n",
       "9                    SPRAIN OR TEAR                   38.0   \n",
       "\n",
       "  WCIO Part Of Body Description  Zip Code  Agreement Reached  \\\n",
       "0                     LOWER LEG     10466                0.0   \n",
       "1          MULTIPLE HEAD INJURY     11691                0.0   \n",
       "2                      BUTTOCKS     10604                0.0   \n",
       "3                          KNEE     11411                0.0   \n",
       "4                         THUMB     11212                0.0   \n",
       "5            NO PHYSICAL INJURY     10941                0.0   \n",
       "6                   SHOULDER(S)     14131                0.0   \n",
       "7                          KNEE     13357                0.0   \n",
       "8                        EYE(S)     11735                0.0   \n",
       "9                   SHOULDER(S)     14720                0.0   \n",
       "\n",
       "  Number of Dependents  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    0  \n",
       "3                    6  \n",
       "4                    5  \n",
       "5                    4  \n",
       "6                    6  \n",
       "7                    4  \n",
       "8                    3  \n",
       "9                    0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a98edc8-d366-4fc4-88dd-52c455932e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dimensions: (593471, 33)\n",
      "Test dimensions: (387975, 31)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dimensions:\", train.shape)\n",
    "print(\"Test dimensions:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebc8dd71-50b6-4b8c-b7d1-525c57079143",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns: Index(['Accident Date', 'Age at Injury', 'Alternative Dispute Resolution',\n",
      "       'Assembly Date', 'Attorney/Representative', 'Average Weekly Wage',\n",
      "       'Birth Year', 'C-2 Date', 'C-3 Date', 'Carrier Name', 'Carrier Type',\n",
      "       'Claim Identifier', 'Claim Injury Type', 'County of Injury',\n",
      "       'COVID-19 Indicator', 'District Name', 'First Hearing Date', 'Gender',\n",
      "       'IME-4 Count', 'Industry Code', 'Industry Code Description',\n",
      "       'Medical Fee Region', 'OIICS Nature of Injury Description',\n",
      "       'WCIO Cause of Injury Code', 'WCIO Cause of Injury Description',\n",
      "       'WCIO Nature of Injury Code', 'WCIO Nature of Injury Description',\n",
      "       'WCIO Part Of Body Code', 'WCIO Part Of Body Description', 'Zip Code',\n",
      "       'Agreement Reached', 'WCB Decision', 'Number of Dependents'],\n",
      "      dtype='object')\n",
      "Test columns: Index(['Accident Date', 'Age at Injury', 'Alternative Dispute Resolution',\n",
      "       'Assembly Date', 'Attorney/Representative', 'Average Weekly Wage',\n",
      "       'Birth Year', 'C-2 Date', 'C-3 Date', 'Carrier Name', 'Carrier Type',\n",
      "       'Claim Identifier', 'County of Injury', 'COVID-19 Indicator',\n",
      "       'District Name', 'First Hearing Date', 'Gender', 'IME-4 Count',\n",
      "       'Industry Code', 'Industry Code Description', 'Medical Fee Region',\n",
      "       'OIICS Nature of Injury Description', 'WCIO Cause of Injury Code',\n",
      "       'WCIO Cause of Injury Description', 'WCIO Nature of Injury Code',\n",
      "       'WCIO Nature of Injury Description', 'WCIO Part Of Body Code',\n",
      "       'WCIO Part Of Body Description', 'Zip Code', 'Agreement Reached',\n",
      "       'Number of Dependents'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Train columns:\", train.columns)\n",
    "print(\"Test columns:\", test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfd93dd3-90c3-42d6-a216-9c1d5abef025",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 593471 entries, 0 to 593470\n",
      "Data columns (total 33 columns):\n",
      " #   Column                              Non-Null Count   Dtype  \n",
      "---  ------                              --------------   -----  \n",
      " 0   Accident Date                       570337 non-null  object \n",
      " 1   Age at Injury                       574026 non-null  float64\n",
      " 2   Alternative Dispute Resolution      574026 non-null  object \n",
      " 3   Assembly Date                       593471 non-null  object \n",
      " 4   Attorney/Representative             574026 non-null  object \n",
      " 5   Average Weekly Wage                 545375 non-null  float64\n",
      " 6   Birth Year                          544948 non-null  float64\n",
      " 7   C-2 Date                            559466 non-null  object \n",
      " 8   C-3 Date                            187245 non-null  object \n",
      " 9   Carrier Name                        574026 non-null  object \n",
      " 10  Carrier Type                        574026 non-null  object \n",
      " 11  Claim Identifier                    593471 non-null  int64  \n",
      " 12  Claim Injury Type                   574026 non-null  object \n",
      " 13  County of Injury                    574026 non-null  object \n",
      " 14  COVID-19 Indicator                  574026 non-null  object \n",
      " 15  District Name                       574026 non-null  object \n",
      " 16  First Hearing Date                  150798 non-null  object \n",
      " 17  Gender                              574026 non-null  object \n",
      " 18  IME-4 Count                         132803 non-null  float64\n",
      " 19  Industry Code                       564068 non-null  float64\n",
      " 20  Industry Code Description           564068 non-null  object \n",
      " 21  Medical Fee Region                  574026 non-null  object \n",
      " 22  OIICS Nature of Injury Description  0 non-null       float64\n",
      " 23  WCIO Cause of Injury Code           558386 non-null  float64\n",
      " 24  WCIO Cause of Injury Description    558386 non-null  object \n",
      " 25  WCIO Nature of Injury Code          558369 non-null  float64\n",
      " 26  WCIO Nature of Injury Description   558369 non-null  object \n",
      " 27  WCIO Part Of Body Code              556944 non-null  float64\n",
      " 28  WCIO Part Of Body Description       556944 non-null  object \n",
      " 29  Zip Code                            545389 non-null  object \n",
      " 30  Agreement Reached                   574026 non-null  float64\n",
      " 31  WCB Decision                        574026 non-null  object \n",
      " 32  Number of Dependents                574026 non-null  float64\n",
      "dtypes: float64(11), int64(1), object(21)\n",
      "memory usage: 149.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "473a7b79-0662-4a28-b153-86c31845b5fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 387975 entries, 0 to 387974\n",
      "Data columns (total 31 columns):\n",
      " #   Column                              Non-Null Count   Dtype  \n",
      "---  ------                              --------------   -----  \n",
      " 0   Accident Date                       385531 non-null  object \n",
      " 1   Age at Injury                       387975 non-null  int64  \n",
      " 2   Alternative Dispute Resolution      387975 non-null  object \n",
      " 3   Assembly Date                       387975 non-null  object \n",
      " 4   Attorney/Representative             387975 non-null  object \n",
      " 5   Average Weekly Wage                 368771 non-null  float64\n",
      " 6   Birth Year                          368505 non-null  float64\n",
      " 7   C-2 Date                            378841 non-null  object \n",
      " 8   C-3 Date                            85216 non-null   object \n",
      " 9   Carrier Name                        387975 non-null  object \n",
      " 10  Carrier Type                        387975 non-null  object \n",
      " 11  Claim Identifier                    387975 non-null  int64  \n",
      " 12  County of Injury                    387975 non-null  object \n",
      " 13  COVID-19 Indicator                  387975 non-null  object \n",
      " 14  District Name                       387975 non-null  object \n",
      " 15  First Hearing Date                  43028 non-null   object \n",
      " 16  Gender                              387975 non-null  object \n",
      " 17  IME-4 Count                         35249 non-null   float64\n",
      " 18  Industry Code                       380239 non-null  float64\n",
      " 19  Industry Code Description           380239 non-null  object \n",
      " 20  Medical Fee Region                  387975 non-null  object \n",
      " 21  OIICS Nature of Injury Description  0 non-null       float64\n",
      " 22  WCIO Cause of Injury Code           377627 non-null  float64\n",
      " 23  WCIO Cause of Injury Description    377627 non-null  object \n",
      " 24  WCIO Nature of Injury Code          377415 non-null  float64\n",
      " 25  WCIO Nature of Injury Description   377415 non-null  object \n",
      " 26  WCIO Part Of Body Code              378426 non-null  float64\n",
      " 27  WCIO Part Of Body Description       378426 non-null  object \n",
      " 28  Zip Code                            368633 non-null  object \n",
      " 29  Agreement Reached                   387975 non-null  float64\n",
      " 30  Number of Dependents                387975 non-null  int64  \n",
      "dtypes: float64(9), int64(3), object(19)\n",
      "memory usage: 91.8+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612a1ff6-f886-486a-bfc9-4a4ab5ea76ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.describe(include ='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a917c10d-8936-498f-b9af-6dcefe043e77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8cf83d-9ec1-4e25-b88d-517026ec7289",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"furtheranalysis\">\n",
    "    \n",
    "## 3.1 Further Analysis\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e86b902-48c8-4d11-9317-c86ff4d1b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('youngest person:',train['Birth Year'].max())\n",
    "print('oldest injured:',train['Age at Injury'].max())\n",
    "print('most dependents:',train['Number of Dependents'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959a574a-78d6-46f5-9a82-4bb2c6922fa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in train.columns:\n",
    "    print(i)\n",
    "    print(train[i].unique())\n",
    "    print(train[i].value_counts())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70410615-1fae-4649-80f7-69bc09573114",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"graphicalrepresentaion\">\n",
    "    \n",
    "### 3.1.1 Graphical Representaion\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ea7ab8-a6f5-4bbc-8a80-747cf6af3d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = train.select_dtypes(include=[object]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cf70a5-2a22-461b-8c81-da1641ab5cdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train[numerical_cols].hist(figsize=(15, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6d90a4-934f-4cde-ada5-02c7177a273d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot( x= 'Claim Injury Type', data = train)\n",
    "plt.title('Distribution of Claim Injury Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc4ac2-cf76-4fc2-ad51-ae6d49c03efe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_matrix = train[numerical_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86632633-ec8c-4161-9245-6830c20b0bd6",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fadfbfb-1003-4013-8eb7-81452a429372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Claim Identifier as index\n",
    "train.set_index('Claim Identifier', inplace=True) \n",
    "test.set_index('Claim Identifier', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97832b33-9605-491f-974a-e420274f6f09",
   "metadata": {},
   "source": [
    "#### Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5465c6f8-e79f-42c4-8365-6874f314fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['WCIO Part Of Body Code'] = train['WCIO Part Of Body Code'].apply(lambda x: 0 if x < 0 else x)\n",
    "test['WCIO Part Of Body Code'] = test['WCIO Part Of Body Code'].apply(lambda x: 0 if x < 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdbfb1a-217a-4b82-9614-4a3ac15966f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = ['Accident Date', 'Assembly Date', 'C-2 Date', 'C-3 Date', 'First Hearing Date']\n",
    "int_cols = ['Age at Injury', 'Birth Year', 'IME-4 Count', 'Number of Dependents']\n",
    "float_to_object = ['Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dae7cd-aba5-4b20-93ea-05bfeafb8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries for mapping codes to descriptions\n",
    "code_maps = {\n",
    "    'Industry Code': train.dropna(subset=['Industry Code', 'Industry Code Description']).set_index('Industry Code')['Industry Code Description'].to_dict(),\n",
    "    'WCIO Cause of Injury Code': train.dropna(subset=['WCIO Cause of Injury Code', 'WCIO Cause of Injury Description']).set_index('WCIO Cause of Injury Code')['WCIO Cause of Injury Description'].to_dict(),\n",
    "    'WCIO Nature of Injury Code': train.dropna(subset=['WCIO Nature of Injury Code', 'WCIO Nature of Injury Description']).set_index('WCIO Nature of Injury Code')['WCIO Nature of Injury Description'].to_dict(),\n",
    "    'WCIO Part Of Body Code': train.dropna(subset=['WCIO Part Of Body Code', 'WCIO Part Of Body Description']).set_index('WCIO Part Of Body Code')['WCIO Part Of Body Description'].to_dict()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5a34e1-9f03-4577-899c-4b9997ec086a",
   "metadata": {},
   "source": [
    "#### Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eeaa98-4341-4547-b142-2575a23b5703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not in test\n",
    "train.drop(['WCB Decision'], inplace = True, axis = 1)\n",
    "# no meaningful values\n",
    "train.drop(['OIICS Nature of Injury Description'], inplace=True, axis=1)\n",
    "test.drop(['OIICS Nature of Injury Description'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237661fb-e142-4732-9556-2e3dc559bdd2",
   "metadata": {},
   "source": [
    "#### Drop Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f411b2-4e41-4c1d-aa38-b27f28acb3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminates the lines that do not have Claim Injury Type\n",
    "train.dropna(subset=['Claim Injury Type'], inplace=True)\n",
    "\n",
    "# Eliminates rows with only 1, 2 or 3 NaN values, as we see that \n",
    "# the 'C-3 Date', 'First Hearing Date' and 'IME-4 Count' columns have +- 70% of the values ‚Äã‚Äãmissing\n",
    "train = train.dropna(thresh=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18212138-d1ed-4e35-9948-d7ff8600b321",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"missingvalues\">\n",
    "    \n",
    "## Missing Values\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb418de3-c601-49d1-801c-95b441cbc7d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msno.matrix(train, labels=True, sort=\"descending\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0448f09-4966-4333-a752-8582297474d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c61413e-1abb-4f72-b703-e8781e10bbb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msno.matrix(test, labels=True, sort=\"descending\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e223dfdd-8b31-4097-a8c7-e3e62afb5f71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b603a56b-6abd-4a40-ab71-a5b94f23a24b",
   "metadata": {},
   "source": [
    "### Data Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a125297-dda4-463b-be5d-902f397084c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, method=None):\n",
    "    splits = []\n",
    "    if method is None:\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X,y, test_size = 0.3, \n",
    "                                                random_state = 0, \n",
    "                                                stratify = y, \n",
    "                                                shuffle = True)\n",
    "        X_train_num = X_train.select_dtypes(include=np.number)\n",
    "        X_val_num = X_val.select_dtypes(include=np.number)\n",
    "        X_train_cat = X_train.select_dtypes(exclude=np.number)\n",
    "        X_val_cat = X_val.select_dtypes(exclude=np.number)\n",
    "        return X_train_num, X_val_num, X_train_cat, X_val_cat, y_train, y_val\n",
    "    elif isinstance(method, StratifiedKFold):\n",
    "        for train_index, test_index in method.split(X, y):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "            splits.append((X_train, X_val, y_train, y_val))\n",
    "    else:\n",
    "        for train_index, test_index in method.split(X):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "            splits.append((X_train, X_val, y_train, y_val))\n",
    "\n",
    "    processed_splits = []\n",
    "    for X_train, X_val, y_train, y_val in splits:\n",
    "        X_train_num = X_train.select_dtypes(include=np.number)\n",
    "        X_val_num = X_val.select_dtypes(include=np.number)\n",
    "        X_train_cat = X_train.select_dtypes(exclude=np.number)\n",
    "        X_val_cat = X_val.select_dtypes(exclude=np.number)\n",
    "        processed_splits.append((X_train_num, X_val_num, X_train_cat, X_val_cat, y_train, y_val))\n",
    "\n",
    "    return processed_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8131b0b-68ff-49c7-b1d9-ddae012aed76",
   "metadata": {},
   "source": [
    "### Pre-Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc74dbbe-e608-4568-b822-f7cbaff91eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datetime(df, date_cols):\n",
    "    for col in date_cols:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18b4b4-eb20-429f-8e50-b695dfab63c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datetime_cols(df, date_cols):\n",
    "    df = df + date_cols\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5f6e33-1418-4e0f-987d-d86952490b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int(df, int_cols):\n",
    "    for col in int_cols:\n",
    "        df[col] = df[col].astype('Int64')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd93f27-edea-49a3-81f5-a47f5142f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_object(df, int_cols):\n",
    "    for col in int_cols:\n",
    "        df[col] = df[col].astype('object')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fe48fa-7097-4e56-a0f0-8cbf514b8f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_num(df):\n",
    "    df_num = df.select_dtypes(include=[np.number, 'datetime64[ns]'])\n",
    "    df_cat = df.select_dtypes(include=['object'])\n",
    "    return df_num, df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e1576d-8e74-44ef-b385-051dd8a282eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(df_num, df_cat):\n",
    "    df = pd.concat([df_num, df_cat], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68215f34-81ee-48a6-a6c1-757bb47d1f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_Imputer(X_train_num, X_val_num, X_test_num, X_train_cat, X_val_cat, X_test_cat, code_maps, float_to_object):\n",
    "    print(\"KNN Imputer: Starting\")\n",
    "\n",
    "    # Select only the float_to_object features for KNN imputation\n",
    "    float_to_object_features = [col for col in float_to_object if col in X_train_num.columns]\n",
    "    print(f\"Float to Object Features: {float_to_object_features}\")\n",
    "\n",
    "    X_train_num_knn = X_train_num[float_to_object_features]\n",
    "    X_val_num_knn = X_val_num[float_to_object_features]\n",
    "    X_test_num_knn = X_test_num[float_to_object_features]\n",
    "\n",
    "    print(f\"X_train_num_knn shape: {X_train_num_knn.shape}\")\n",
    "    print(f\"X_val_num_knn shape: {X_val_num_knn.shape}\")\n",
    "    print(f\"X_test_num_knn shape: {X_test_num_knn.shape}\")\n",
    "\n",
    "    # Impute missing values in float_to_object features using KNN\n",
    "    imputer = KNNImputer(n_neighbors=1).fit(X_train_num_knn)\n",
    "    train_num_imp_knn = imputer.transform(X_train_num_knn)\n",
    "    val_num_imp_knn = imputer.transform(X_val_num_knn)\n",
    "    test_num_imp_knn = imputer.transform(X_test_num_knn)\n",
    "\n",
    "    print(f\"Train Num Imp KNN shape: {train_num_imp_knn.shape}\")\n",
    "    print(f\"Val Num Imp KNN shape: {val_num_imp_knn.shape}\")\n",
    "    print(f\"Test Num Imp KNN shape: {test_num_imp_knn.shape}\")\n",
    "\n",
    "    # Convert imputed numerical features back to DataFrames\n",
    "    train_num_df_knn = pd.DataFrame(train_num_imp_knn, columns=X_train_num_knn.columns, index=X_train_num_knn.index)\n",
    "    val_num_df_knn = pd.DataFrame(val_num_imp_knn, columns=X_val_num_knn.columns, index=X_val_num_knn.index)\n",
    "    test_num_df_knn = pd.DataFrame(test_num_imp_knn, columns=X_test_num_knn.columns, index=X_test_num_knn.index)\n",
    "\n",
    "    print(f\"Train Num DF KNN shape: {train_num_df_knn.shape}\")\n",
    "    print(f\"Val Num DF KNN shape: {val_num_df_knn.shape}\")\n",
    "    print(f\"Test Num DF KNN shape: {test_num_df_knn.shape}\")\n",
    "\n",
    "    # Replace the original float_to_object features with the imputed ones\n",
    "    X_train_num[float_to_object_features] = train_num_df_knn\n",
    "    X_val_num[float_to_object_features] = val_num_df_knn\n",
    "    X_test_num[float_to_object_features] = test_num_df_knn\n",
    "\n",
    "    # Combine numerical and categorical features\n",
    "    train_combined = combine(X_train_num, X_train_cat)\n",
    "    val_combined = combine(X_val_num, X_val_cat)\n",
    "    test_combined = combine(X_test_num, X_test_cat)\n",
    "\n",
    "    print(train_combined.columns)\n",
    "    \n",
    "    # Map codes to descriptions\n",
    "    for code, map_dict in code_maps.items():\n",
    "        code_name = code.replace(' Code', '')\n",
    "        if f'{code_name} Description' in train_combined.columns:\n",
    "            print(f\"Mapping code {code} to description\")\n",
    "            train_combined[f'{code_name} Description'] = train_combined[code].map(map_dict).fillna(train_combined[f'{code_name} Description'])\n",
    "            val_combined[f'{code_name} Description'] = val_combined[code].map(map_dict).fillna(val_combined[f'{code_name} Description'])\n",
    "            test_combined[f'{code_name} Description'] = test_combined[code].map(map_dict).fillna(test_combined[f'{code_name} Description'])\n",
    "        else:\n",
    "            print(f\"Column {code_name} Description does not exist\")\n",
    "\n",
    "    X_train_num = train_combined.select_dtypes(include=np.number)\n",
    "    X_val_num = val_combined.select_dtypes(include=np.number)\n",
    "    X_test_num = test_combined.select_dtypes(include=np.number)\n",
    "    X_train_cat = train_combined.select_dtypes(exclude=np.number)\n",
    "    X_val_cat = val_combined.select_dtypes(exclude=np.number)\n",
    "    X_test_cat = test_combined.select_dtypes(exclude=np.number)\n",
    "\n",
    "    return X_train_num, X_val_num, X_test_num, X_train_cat, X_val_cat, X_test_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d20563-60d8-4d33-919c-1ec8077492b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputing(X_train_num, X_val_num, X_test_num, X_train_cat, X_val_cat, X_test_cat):\n",
    "   \n",
    "    print(\"Num median imputing: Starting\")\n",
    "    #Using median for numerical data\n",
    "    num_imputer = SimpleImputer(strategy=\"median\")\n",
    "    X_train_num = pd.DataFrame(num_imputer.fit_transform(X_train_num), columns=X_train_num.columns)\n",
    "    X_val_num = pd.DataFrame(num_imputer.transform(X_val_num), columns=X_val_num.columns)\n",
    "    X_test_num = pd.DataFrame(num_imputer.transform(X_test_num), columns=X_test_num.columns)\n",
    "\n",
    "    print(\"Cat most frequent imputing: Starting\")\n",
    "    #Using most frequent for categorical data\n",
    "    cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    X_train_cat = pd.DataFrame(cat_imputer.fit_transform(X_train_cat), columns=X_train_cat.columns)\n",
    "    X_val_cat = pd.DataFrame(cat_imputer.transform(X_val_cat), columns=X_val_cat.columns)\n",
    "    X_test_cat = pd.DataFrame(cat_imputer.transform(X_test_cat), columns=X_test_cat.columns)\n",
    "\n",
    "    return X_train_num, X_val_num, X_test_num, X_train_cat, X_val_cat, X_test_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953117e4-07d1-4c77-820c-d34965cde95b",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a3eb77-8bbe-44c4-82b7-ebd950193ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train, test):\n",
    "    \n",
    "    train = convert_to_datetime(train, date_cols)\n",
    "    test = convert_to_datetime(test, date_cols)\n",
    "\n",
    "    train = convert_to_int(train, int_cols)\n",
    "    test = convert_to_int(test, int_cols)\n",
    "\n",
    "    train = convert_to_int(train, float_to_object)\n",
    "    test = convert_to_int(test, float_to_object)\n",
    "    \n",
    "    X_test_num, X_test_cat = cat_num(test)\n",
    "\n",
    "    y = train['Claim Injury Type']\n",
    "    X = train.drop('Claim Injury Type', axis=1)\n",
    "\n",
    "    splits = split_data(X, y, method=None)\n",
    "    X_train_num, X_val_num, X_train_cat, X_val_cat, y_train, y_val = splits[0]\n",
    "\n",
    "    X_train_num, X_val_num, X_test_num, X_train_cat, X_val_cat, X_test_cat = KNN_Imputer(X_train_num, X_val_num,\n",
    "                                                                                         X_test_num, X_train_cat,\n",
    "                                                                                         X_val_cat, X_test_cat, \n",
    "                                                                                         code_maps, float_to_object)\n",
    "    \n",
    "    X_train_num, X_val_num, X_test_num, X_train_cat, X_val_cat, X_test_cat = imputing(X_train_num, X_val_num,\n",
    "                                                                                      X_test_num, X_train_cat,\n",
    "                                                                                      X_val_cat, X_test_cat)\n",
    "\n",
    "    X_train = combine(X_train_num, X_train_cat)\n",
    "    X_val = combine(X_val_num, X_val_cat)\n",
    "    X_test = combine(X_test_num, X_test_cat)\n",
    "\n",
    "    X_train = convert_to_object(X_train, float_to_object)\n",
    "    X_val = convert_to_object(X_val, float_to_object)\n",
    "    X_test = convert_to_object(X_test, float_to_object)\n",
    "\n",
    "    return X_train, X_val, y_train, y_val, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcb0b9e-9941-4547-ac7d-54934901d85b",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"datapreprocessing\">\n",
    "    \n",
    "# 4. Feature Engineering\n",
    "    \n",
    "</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbb6cd2-a1e6-4699-8189-b1f66e256fef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df, feature_set='basic'):\n",
    "    df = df.copy()\n",
    "    print(f\"Initial shape: {df.shape}\")\n",
    "    \n",
    "    # Date feature engineering\n",
    "    for col in date_cols:\n",
    "        \n",
    "        # Extract year, month, and day\n",
    "        df[f'{col}_Year'] = df[col].dt.year\n",
    "        df[f'{col}_Month'] = df[col].dt.month\n",
    "        df[f'{col}_Day'] = df[col].dt.day\n",
    "    \n",
    "    # Date feature engineering\n",
    "    df['Assembly_to_Accident'] = (df['Assembly Date'] - df['Accident Date']).dt.days\n",
    "    df['C2_to_Accident'] = (df['C-2 Date'] - df['Accident Date']).dt.days\n",
    "    df['C3_to_Accident'] = (df['C-3 Date'] - df['Accident Date']).dt.days\n",
    "    df['Hearing_to_Accident'] = (df['First Hearing Date'] - df['Accident Date']).dt.days\n",
    "\n",
    "    # Age-based features\n",
    "    df['Age_at_Assembly'] = df['Age at Injury'] + (df['Assembly Date'] - df['Accident Date']).dt.days / 365\n",
    "    df['Age_at_C2'] = df['Age at Injury'] + (df['C-2 Date'] - df['Accident Date']).dt.days / 365\n",
    "    df['Age_at_C3'] = df['Age at Injury'] + (df['C-3 Date'] - df['Accident Date']).dt.days / 365\n",
    "    df['Age_at_Hearing'] = df['Age at Injury'] + (df['First Hearing Date'] - df['Accident Date']).dt.days / 365\n",
    "    \n",
    "    # Additional feature engineering\n",
    "    if 'Average Weekly Wage' in df.columns:\n",
    "        # Fill missing values with the median wage\n",
    "        df['Average Weekly Wage'] = df['Average Weekly Wage'].fillna(df['Average Weekly Wage'].median())\n",
    "    \n",
    "        # Create a temporary column for wages greater than 0\n",
    "        positive_wages = df['Average Weekly Wage'] > 0\n",
    "    \n",
    "        # Apply qcut to positive wages only\n",
    "        wage_groups = pd.qcut(\n",
    "            df.loc[positive_wages, 'Average Weekly Wage'], \n",
    "            q=10, \n",
    "            labels=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "        )\n",
    "    \n",
    "    # Assign the results back to the dataframe\n",
    "    df['Wage_Group'] = 0  # Default to 0 (avg weekly wage = 0)\n",
    "    df.loc[positive_wages, 'Wage_Group'] = wage_groups.astype(int)  # Overwrite for positive wages\n",
    "    \n",
    "    # assume 'df' is your DataFrame with the county names\n",
    "    df['Distance to NYC'] = df['District Name'].map({\n",
    "        'NYC': 0,\n",
    "        'ALBANY': 155,\n",
    "        'HAUPPAUGE': 45,\n",
    "        'BUFFALO': 373,\n",
    "        'SYRACUSE': 198,\n",
    "        'ROCHESTER': 338,\n",
    "        'BINGHAMTON': 173\n",
    "    })\n",
    "\n",
    "    mean_distance = df[df['District Name'] != 'STATEWIDE']['Distance to NYC'].mean()\n",
    "    df.loc[df['District Name'] == 'STATEWIDE', 'Distance to NYC'] = mean_distance\n",
    "\n",
    "    # Assuming df_train is your DataFrame\n",
    "    counties = { \"SUFFOLK\": 45.4, \"QUEENS\": 8.5, \"KINGS\": 7.5, \"NASSAU\": 20.1,\n",
    "            \"BRONX\": 10.3, \"ERIE\": 371.1, \"NEW YORK\": 0, \"WESTCHESTER\": 20.5,\n",
    "            \"MONROE\": 334.8, \"ORANGE\": 59.5, \"ONONDAGA\": 194.8, \"RICHMOND\": 17.1,\n",
    "            \"ALBANY\": 155.1, \"DUTCHESS\": 76.3, \"ROCKLAND\": 30.8, \"SARATOGA\": 143.1, \n",
    "            \"NIAGARA\": 373.9, \"BROOME\": 173.1, \"ONEIDA\": 203.1, \"RENSSELAER\": 145.9, \n",
    "            \"ULSTER\": 86.3, \"CAYUGA\": 221.9, \"HERKIMER\": 213.9, \"CHAUTAUQUA\": 407.9, \n",
    "            \"ONTARIO\": 264.9, \"CHEMUNG\": 201.9, \"OSWEGO\": 243.9, \"FULTON\": 223.1, \n",
    "            \"PUTNAM\": 51.9, \"ST. LAWRENCE\": 314.9, \"JEFFERSON\": 341.1, \"CLINTON\": 304.9, \n",
    "            \"CATTARAUGUS\": 371.9, \"SULLIVAN\": 97.3, \"GENESEE\": 344.9, \"COLUMBIA\": 120.1,\n",
    "            \"MADISON\": 193.9, \"WARREN\": 194.9, \"LIVINGSTON\": 276.9, \"DELAWARE\": 137.1,\n",
    "            \"WASHINGTON\": 204.9, \"GREENE\": 124.9, \"ALLEGANY\": 346.9, \"WAYNE\": 294.9,\n",
    "            \"CHENANGO\": 181.9, \"TOMPKINS\": 209.9, \"ORLEANS\": 323.9, \"SCHENECTADY\": 156.1,\n",
    "            \"FRANKLIN\": 294.9, \"SENECA\": 234.9, \"LEWIS\": 266.9, \"TIOGA\": 187.1, \"STEUBEN\": 246.9, \n",
    "            \"ESSEX\": 214.9, \"SCHUYLER\": 206.1, \"OTSEGO\": 165.1, \"CORTLAND\": 193.9, \n",
    "            \"WYOMING\": 313.9, \"MONTGOMERY\": 173.9, \"SCHOHARIE\": 146.1, \"YATES\": 243.9,\"HAMILTON\": 221.9\n",
    "    }\n",
    "\n",
    "    # Create a list of distances\n",
    "    distances = list(counties.values())\n",
    "\n",
    "    # Calculate the mean distance\n",
    "    mean_distance = statistics.mean(distances)\n",
    "\n",
    "    # Add the \"UNKNOWN\" county to the dictionary with the mean distance\n",
    "    counties[\"UNKNOWN\"] = mean_distance\n",
    "\n",
    "    # Create a new column in the df_train DataFrame called distance_of_county\n",
    "    df['distance_of_county'] = df['County of Injury'].map(counties).fillna(mean_distance)\n",
    "\n",
    "    print(f\"Shape after feature engineering: {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7c2f7d-1893-4b35-9d97-a19f0a39c811",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"outliers\">\n",
    "    \n",
    "## 4.4 Outliers\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adcfa09-8309-4e11-96e2-bba52a9250d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = {\n",
    "    'Age at Injury': {'min': 14, 'max': 90},\n",
    "    'Birth Year': {'iqr': 1.5},\n",
    "    'Average Weekly Wage': {'iqr': 1.5, 'non_zero': True},\n",
    "    'Accident Date': {'date': '1980-01-01'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d401b6-fab9-485a-ae60-61b9f2e0c91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df, columns, rules, train=False):\n",
    "    cleaned_df = df.copy()\n",
    "\n",
    "    for column in columns:\n",
    "        if column in rules:\n",
    "            rule = rules[column]\n",
    "            if 'min' in rule and 'max' in rule:\n",
    "                cleaned_df = cleaned_df[(cleaned_df[column] >= rule['min']) & (cleaned_df[column] <= rule['max'])]\n",
    "            elif 'iqr' in rule:\n",
    "                if train:\n",
    "                    Q1 = df[column].quantile(0.25)\n",
    "                    Q3 = df[column].quantile(0.75)\n",
    "                    IQR = Q3 - Q1\n",
    "                    lower_bound = Q1 - rule['iqr'] * IQR\n",
    "                    upper_bound = Q3 + rule['iqr'] * IQR\n",
    "                    rule['min'] = lower_bound\n",
    "                    rule['max'] = upper_bound\n",
    "                cleaned_df = cleaned_df[(cleaned_df[column] >= rule['min']) & (cleaned_df[column] <= rule['max'])]\n",
    "            elif 'non_zero' in rule:\n",
    "                cleaned_df = cleaned_df[cleaned_df[column] != 0]\n",
    "            elif 'date' in rule:\n",
    "                cleaned_df = cleaned_df[cleaned_df[column] > pd.to_datetime(rule['date'])]\n",
    "\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ac1b0-423c-4d5c-9d81-c043f363aadb",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bc55e1-8536-4618-8732-b91be2daec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(train, val, test, y_train, y_val, encoding = 'ordinal'):\n",
    "    X_train_num, X_train_cat = cat_num(train)\n",
    "    X_val_num, X_val_cat = cat_num(val)\n",
    "    X_test_num, X_test_cat = cat_num(test)\n",
    "    \n",
    "    if encoding == 'ordinal':\n",
    "        enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    elif encoding == 'onehot':\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid encoding type. Please choose 'ordinal' or 'onehot'.\")\n",
    "\n",
    "    encoded_train = pd.DataFrame(enc.fit_transform(X_train_cat).astype(str))\n",
    "    encoded_val = pd.DataFrame(enc.transform(X_val_cat).astype(str))\n",
    "    encoded_test = pd.DataFrame(enc.transform(X_test_cat).astype(str))\n",
    "\n",
    "    encoded_train.columns = [f'encoded_{i}' for i in range(encoded_train.shape[1])]\n",
    "    encoded_val.columns = [f'encoded_{i}' for i in range(encoded_val.shape[1])]\n",
    "    encoded_test.columns = [f'encoded_{i}' for i in range(encoded_test.shape[1])]\n",
    "\n",
    "    enc2 = LabelEncoder() #encoder for labels\n",
    "    y_train = enc2.fit_transform(y_train)\n",
    "    y_val = enc2.transform(y_val)\n",
    "\n",
    "    X_train = combine(X_train_num, encoded_train)\n",
    "    X_val = combine(X_val_num, encoded_val)\n",
    "    X_test = combine(X_test_num, encoded_test)\n",
    "    \n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0f5249-8a38-41ba-93ac-5da396658658",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"scaling\">\n",
    "    \n",
    "## 4.7 Scaling\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8b66fe-9914-4f2b-b150-c372f753a888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scaler_method(method='minmax'):\n",
    "    \n",
    "    if method == 'minmax':\n",
    "        return MinMaxScaler()\n",
    "    elif method == 'standard':\n",
    "        return StandardScaler()\n",
    "    elif method == 'robust':\n",
    "        return RobustScaler()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid scaling method. Options are 'minmax' and 'standard'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed421119-0286-42ca-9490-0a84958a5be5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_val, X_test, method='minmax'):\n",
    "    \n",
    "    scaler = scaler_method(method)\n",
    "    \n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), index=X_train.index, columns=X_train.columns)\n",
    "    X_val_scaled = pd.DataFrame(scaler.transform(X_val), index=X_val.index, columns=X_val.columns)\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n",
    "    \n",
    "    return X_train_scaled, X_val_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd21b323-3a0a-4fb0-9385-dc80f233eac5",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"featureselection\">\n",
    "    \n",
    "# 5. Feature selection\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69edb28d-ffe2-48f8-8a2b-357d200b36dd",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"correlations\">\n",
    "    \n",
    "## 5.1 Correlations\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c20eeb-c3ff-48f4-823f-a6612bd80fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_heatmap(data):\n",
    "    \n",
    "    corr = data.corr(method='pearson')\n",
    "    \n",
    "    corr_masked = corr.copy()\n",
    "    corr_masked[(corr_masked > -0.5) & (corr_masked < 0.5)] = np.nan\n",
    "\n",
    "    mask = np.triu(np.ones_like(corr_masked, dtype=bool))\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(12, 10))\n",
    "    sns.heatmap(corr, mask=mask, cmap='RdBu', vmax=1, vmin=-1, center=0,\n",
    "                square=True, annot=True, annot_kws={'size': 10}, linewidths=0.5, cbar_kws={\"shrink\": 0.5},\n",
    "                fmt='.1f')\n",
    "\n",
    "    for text in ax.texts:\n",
    "        if abs(float(text.get_text())) < 0.3:\n",
    "            text.set_text('') \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "cor_heatmap(X_train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907ce814-3d6b-443b-9b94-53f896ebdaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_corr(X_train, X_val, X_test, threshold=0.8):\n",
    "    corr = X_train.corr(method='pearson')\n",
    "    corr_masked = corr.copy()\n",
    "    corr_masked[(corr_masked > -threshold) & (corr_masked < threshold)] = np.nan\n",
    "\n",
    "    to_drop = []\n",
    "    for i in range(len(corr.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr.iloc[i, j]) > threshold:\n",
    "                if corr.columns[j] not in to_drop:\n",
    "                    to_drop.append(corr.columns[j])\n",
    "                break\n",
    "\n",
    "    X_train_dropped = X_train.drop(to_drop, axis=1)\n",
    "    X_val_dropped = X_val.drop(to_drop, axis=1)\n",
    "    X_test_dropped = X_test.drop(to_drop, axis=1)\n",
    "    \n",
    "    return X_train_dropped, X_val_dropped, X_test_dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d72a8b9-7dd9-4a17-b76b-0750f65b9c39",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"chisquare\">\n",
    "    \n",
    "## 5.2 Chi-Square\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48287e7-0045-4d6c-8c33-7a4699749561",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#is not giving relevant information for now\n",
    "def TestIndependence(X,y,var,alpha=0.05):        \n",
    "    dfObserved = pd.crosstab(y,X) \n",
    "    chi2, p, dof, expected = stats.chi2_contingency(dfObserved.values)\n",
    "    dfExpected = pd.DataFrame(expected, columns=dfObserved.columns, index = dfObserved.index)\n",
    "    if p<alpha:\n",
    "        result=p, \"{0} is IMPORTANT for Prediction\".format(var)\n",
    "    else:\n",
    "        result=p, \"{0} is NOT an important predictor. (Discard {0} from model)\".format(var)\n",
    "    print(result)\n",
    "\n",
    "for var in X_train_cat_df:\n",
    "    TestIndependence(X_train_cat_df[var],y_train, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14a23c7-7e8d-4f8b-8e1e-822c77e95dff",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"lassocv\">\n",
    "    \n",
    "## 5.3 LassoCV\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0033ed3-a40e-4d34-a223-f0c5b368743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(coef,name):\n",
    "    imp_coef = coef.sort_values()\n",
    "    plt.figure(figsize=(8,10))\n",
    "    imp_coef.plot(kind = \"barh\")\n",
    "    plt.title(\"Feature importance using \" + name + \" Model\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74085492-3452-48de-bbe7-0a98c8455b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_lasso(X_train, X_val, X_test, y_train):\n",
    "    \n",
    "    reg = LassoCV()\n",
    "    reg.fit(X_train, y_train)\n",
    "    coef = pd.Series(reg.coef_, index=X_train.columns)\n",
    "    \n",
    "    columns_to_keep = coef[coef != 0].index\n",
    "    \n",
    "    X_train_columns_to_keep = X_train[columns_to_keep]\n",
    "    X_val_columns_to_keep = X_val[columns_to_keep]\n",
    "    X_test_columns_to_keep = X_test[columns_to_keep]\n",
    "    \n",
    "    return X_train_columns_to_keep, X_val_columns_to_keep, X_test_columns_to_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4418a8-72d2-4357-bee2-5c59ab805714",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deefbff9-7eb7-4f18-bd05-ef205fcd2e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_dt(X_train, X_val, X_test, y_train, n_to_drop=2):\n",
    "    \n",
    "    # Calculate feature importances using Gini and Entropy\n",
    "    gini_importance = DecisionTreeClassifier().fit(X_train, y_train).feature_importances_\n",
    "    entropy_importance = DecisionTreeClassifier(criterion='entropy').fit(X_train, y_train).feature_importances_\n",
    "\n",
    "    # Create a dataframe with the feature importances\n",
    "    zippy = pd.DataFrame(zip(gini_importance, entropy_importance), columns=['gini', 'entropy'])\n",
    "    zippy['col'] = X_train.columns\n",
    "    tidy = zippy.melt(id_vars='col').rename(columns=str.title)\n",
    "\n",
    "    # Sort the features by importance and select the least valuable ones\n",
    "    least_valuable = tidy.sort_values('Value', ascending=True).head(n_to_drop)\n",
    "\n",
    "    # Drop the least valuable features from the training, validation, and testing data\n",
    "    X_train_dropped = X_train.drop(least_valuable['col'].values, axis=1)\n",
    "    X_val_dropped = X_val.drop(least_valuable['col'].values, axis=1)\n",
    "    X_test_dropped = X_test.drop(least_valuable['col'].values, axis=1)\n",
    "\n",
    "    return X_train_dropped, X_val_dropped, X_test_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96115a93-e8f0-4eac-8a49-ecb4fac4efb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assume X_train and y_train are your training data and labels\n",
    "# Get the unique class labels in y_train\n",
    "class_labels = np.unique(y_train)\n",
    "\n",
    "# Melt the data into a long format\n",
    "melted_data = pd.melt(X_train_columns_to_keep, value_vars=X_train_columns_to_keep.columns, var_name=\"feature\", value_name=\"value\")\n",
    "\n",
    "# Repeat y_train for each value in the melted data\n",
    "repeated_y_train = np.repeat(y_train, len(X_train_columns_to_keep.columns))\n",
    "\n",
    "# Add the repeated class labels to the melted data\n",
    "melted_data[\"class\"] = repeated_y_train\n",
    "\n",
    "# Plot a facet grid with KDEs for each feature and class label\n",
    "sns.set(style=\"whitegrid\")\n",
    "g = sns.FacetGrid(melted_data, col=\"feature\", hue=\"class\", col_wrap=4)\n",
    "g.map(sns.kdeplot, \"value\")\n",
    "g.set(xlim=(-3, 3.5))  # Set the x-axis range to -3-3\n",
    "g.set(ylim=(0, 3))  # Set the y-axis range to 0-0.5\n",
    "g.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a94453e-931b-451f-b0f8-af0bc3fd359a",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"balancingdata\">\n",
    "    \n",
    "## 5.4 Balancing Data\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bc2739-3f19-40de-b564-6d23d8d991d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def custom_sampling_strategy(y):\n",
    "    class_counts = np.bincount(y)\n",
    "    max_count = np.max(class_counts)\n",
    "    sampling_strategy = {}\n",
    "    for i, count in enumerate(class_counts):\n",
    "        if i in [5, 6, 7]:  # minority classes\n",
    "            sampling_strategy[i] = 4000\n",
    "        else:\n",
    "            sampling_strategy[i] = count  # use the original count for other classes\n",
    "    return sampling_strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd98758-e30f-4c32-b59f-ea6199d71a6d",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81507cb6-2bf0-4820-a2b9-3d09d524362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(train, test):\n",
    "\n",
    "    #pre-processing\n",
    "    X_train, X_val, y_train, y_val, test = preprocess_data(train, test)\n",
    "\n",
    "    #feature engineering\n",
    "    X_train = feature_engineering(X_train, feature_set='basic')\n",
    "    X_val = feature_engineering(X_val, feature_set='basic')\n",
    "    X_test = feature_engineering(test, feature_set='basic')\n",
    "\n",
    "    #creates rules for training data\n",
    "    X_train = clean_data(X_train, ['Age at Injury', 'Birth Year', 'Average Weekly Wage', 'Accident Date'], rules, train=True)\n",
    "    \n",
    "    #utilizes the rules created for training data on validation data\n",
    "    X_val = clean_data(X_val, ['Age at Injury', 'Birth Year', 'Average Weekly Wage', 'Accident Date'], rules)\n",
    "\n",
    "    #encoding\n",
    "    X_train, X_val, X_test, y_train, y_val = encode(X_train, X_val, X_test, y_train, y_val, encoding = 'ordinal')\n",
    "\n",
    "    #scaling\n",
    "    scaler = scaler_method('standard')\n",
    "    X_train, X_val, X_test = scale_data(X_train, X_val, X_test, 'standard')\n",
    "\n",
    "    #feature selection\n",
    "    #correlation\n",
    "    X_train, X_val, X_test = selection_corr(X_train, X_val, X_test, threshold = 0.8)\n",
    "\n",
    "    #lasso\n",
    "    X_train, X_val, X_test = selection_lasso(X_train, X_val, X_test, y_train)\n",
    "\n",
    "    #decision trees\n",
    "    X_train, X_val, X_test = selection_dt(X_train, X_val, X_test, y_train, n_to_drop = 2)\n",
    "\n",
    "    #balancing\n",
    "    smote = SMOTE(random_state=42, sampling_strategy=custom_sampling_strategy)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79729c8-e394-467f-9218-821e2dd03c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val = pipeline(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64dc593-f236-4a4b-a4df-a2079b6d90c3",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e2f7d3-881a-4af9-ac7b-803516499f14",
   "metadata": {},
   "source": [
    "#### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da958881-2844-48a4-9f5a-3927025c4ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(X_train, y_train, random_state=42):\n",
    "    \"\"\"Train XGB model\"\"\"\n",
    "    print(\"\\nTraining XGB model...\")\n",
    "    print(f\"Starting training with {X_train.shape[1]} features...\")\n",
    "    \n",
    "    model = XGBClassifier(\n",
    "        n_estimators=250,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6,\n",
    "        random_state=random_state,\n",
    "        n_jobs=2,\n",
    "        tree_method='hist',\n",
    "        enable_categorical=True,\n",
    "        objective='multi:softprob',\n",
    "        num_class=8,\n",
    "        eval_metric=['mlogloss', 'merror'],\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "    \n",
    "    # Train with early stopping\n",
    "    eval_set = [(X_train, y_train)]\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=eval_set,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361f7668-b383-4ac5-b60b-bac5192226fc",
   "metadata": {},
   "source": [
    "#### Histogram Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aba9184-8c15-4798-a43c-8b05c3785df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hist_gb(X_train, y_train, random_state=42):\n",
    "    \"\"\"Train HistGB model\"\"\"\n",
    "    print(\"\\nTraining HistGB model...\")\n",
    "    print(f\"Starting training with {X_train.shape[1]} features...\")\n",
    "    \n",
    "    model = HistGradientBoostingClassifier(\n",
    "        max_iter=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=None,\n",
    "        random_state=random_state,\n",
    "        verbose=1\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1422043c-5ab4-4358-81b0-b6ed90e7a7d7",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ce9d43-7788-4d8a-9f71-634826a94501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simple_rf(X_train, y_train, random_state=42):\n",
    "    \"\"\"Train Simple RF model\"\"\"\n",
    "    print(\"\\nTraining Simple RF model...\")\n",
    "    print(f\"Starting training with {X_train.shape[1]} features...\")\n",
    "    \n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=random_state,\n",
    "        n_jobs=2,\n",
    "        verbose=1,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082663b8-70b0-46a7-8067-dd6018dd6bcb",
   "metadata": {},
   "source": [
    "#### Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78251df7-6239-4add-bfcd-a3bb341c4d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gaussian_nb(X_train, y_train):\n",
    "    \"\"\"Train GaussianNB model\"\"\"\n",
    "    print(\"\\nTraining GaussianNB model...\")\n",
    "    print(f\"Starting training with {X_train.shape[1]} features...\")\n",
    "    \n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f16b80-23c8-49f9-9b7f-dfad073ff057",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeeff8c-35eb-4c8b-ab1a-bf7474c46998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X_train, y_train):\n",
    "    \"\"\"Train Logistic Regression model\"\"\"\n",
    "    print(\"\\nTraining Logistic Regression model...\")\n",
    "    print(f\"Starting training with {X_train.shape[1]} features...\")\n",
    "    \n",
    "    model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0525fd-70e2-4d97-96e0-43fb76f792d2",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"evaluate\">\n",
    "    \n",
    "# 6.2 Evaluate the model\n",
    "    \n",
    "</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ef4443-f62e-4856-ab94-01621ee49327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report(X_train, y_train, X_val, y_val, X_test):\n",
    "    models = {\n",
    "        'LogisticRegression': modelLR,\n",
    "        'XGB': modelXGB,\n",
    "        'HistGB': modelHGB,\n",
    "        'RF': modelRF,\n",
    "        'GaussianNB': modelCNB\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "    best_report = None\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"Model: {name}\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        report = classification_report(y_val, y_pred)\n",
    "        print(report)\n",
    "        score = f1_score(y_val, y_pred, average='macro')\n",
    "        print(f\"F1-score: {score:.4f}\")\n",
    "        print()\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_model = model\n",
    "            best_report = report\n",
    "\n",
    "    print(f\"Best model: {best_model.__class__.__name__}\")\n",
    "    print(\"Best classification report:\")\n",
    "    print(best_report)\n",
    "    print(\"Test prediction:\")\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    \n",
    "    return test_pred, best_model\n",
    "\n",
    "test_pred, best_model = classification_report(X_train, y_train, X_val, y_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f89ef91-97d6-43dd-bd92-4d2149e445f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Get predicted probabilities on the validation set\n",
    "y_pred_proba = model.predict_proba(X_val_columns_to_keep)\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "y_true_onehot = encoder.fit_transform(y_val)\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "for i in range(y_true_onehot.shape[1]):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true_onehot[:, i], y_pred_proba[:, i])\n",
    "    plt.plot(fpr, tpr, label=f'Class {i} (area = {auc(fpr, tpr):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a0e393-3e6a-42e4-9996-21cd080aa8db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_val, y_val, X_test=None):\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    val_metrics = {\n",
    "        'accuracy': accuracy_score(y_val, y_val_pred),\n",
    "        'f1_macro': f1_score(y_val, y_val_pred, average='macro')\n",
    "    }\n",
    "    \n",
    "    print(\"\\nValidation Results:\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    print(\"\\nMetrics:\")\n",
    "    for metric, value in val_metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    test_pred = None\n",
    "    if X_test is not None:\n",
    "        test_pred = model.predict(X_test)\n",
    "    \n",
    "    return val_metrics, test_pred\n",
    "    \n",
    "val_metrics, test_pred = evaluate_model(model, X_val_combined_scaled, y_val, X_test_combined_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c79219-872b-4b35-8b79-cd6c496777b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_val, y_val, X_test=None):\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    val_metrics = {\n",
    "        'accuracy': accuracy_score(y_val, y_val_pred),\n",
    "        'f1_macro': f1_score(y_val, y_val_pred, average='macro')\n",
    "    }\n",
    "    \n",
    "    print(\"\\nValidation Results:\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    print(\"\\nMetrics:\")\n",
    "    for metric, value in val_metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    test_pred = None\n",
    "    if X_test is not None:\n",
    "        test_pred = model.predict(X_test)\n",
    "    \n",
    "    return val_metrics, test_pred\n",
    "    \n",
    "val_metrics, test_pred = evaluate_model(modelLR, X_val_combined_scaled, y_val, X_test_combined_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d37f6cc-2422-4b5e-98dc-b0254173ad92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_val, y_val, X_test=None, threshold_2=0.5, threshold_5=0.5, threshold_6=0.5):\n",
    "    y_val_pred_proba = model.predict_proba(X_val)\n",
    "    y_val_pred = np.argmax(y_val_pred_proba, axis=1)\n",
    "    \n",
    "    # Adjust the threshold for classes 2, 5, and 6\n",
    "    for i, proba in enumerate(y_val_pred_proba):\n",
    "        if y_val[i] == 2 and proba[2] >= threshold_2:\n",
    "            y_val_pred[i] = 2\n",
    "        elif y_val[i] == 5 and proba[5] >= threshold_5:\n",
    "            y_val_pred[i] = 5\n",
    "        elif y_val[i] == 6 and proba[6] >= threshold_6:\n",
    "            y_val_pred[i] = 6\n",
    "    \n",
    "    val_metrics = {\n",
    "        'accuracy': accuracy_score(y_val, y_val_pred),\n",
    "        'f1_macro': f1_score(y_val, y_val_pred, average='macro')\n",
    "    }\n",
    "    \n",
    "    print(\"\\nValidation Results:\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    print(\"\\nMetrics:\")\n",
    "    for metric, value in val_metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    test_pred = None\n",
    "    if X_test is not None:\n",
    "        y_test_pred_proba = model.predict_proba(X_test)\n",
    "        y_test_pred = np.argmax(y_test_pred_proba, axis=1)\n",
    "        \n",
    "        # Adjust the threshold for classes 2, 5, and 6\n",
    "        for i, proba in enumerate(y_test_pred_proba):\n",
    "            if proba[2] >= threshold_2:\n",
    "                y_test_pred[i] = 2\n",
    "            elif proba[5] >= threshold_5:\n",
    "                y_test_pred[i] = 5\n",
    "            elif proba[6] >= threshold_6:\n",
    "                y_test_pred[i] = 6\n",
    "        \n",
    "        test_pred = y_test_pred\n",
    "    \n",
    "    return val_metrics, test_pred\n",
    "\n",
    "val_metrics, test_pred = evaluate_model(model, X_val_columns_to_keep, y_val, X_test_columns_to_keep, threshold_2=0.1, threshold_5=0.1, threshold_6=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b11d4e0-92aa-4ba0-b3b6-383ca92acecf",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"export\">\n",
    "    \n",
    "# 6.3 Export the predictor\n",
    "    \n",
    "</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b756a3e-c5bd-4019-a78d-2439414fd8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAIM_TYPE_MAPPING = {\n",
    "    1: '1. CANCELLED',\n",
    "    2: '2. NON-COMP',\n",
    "    3: '3. MED ONLY',\n",
    "    4: '4. TEMPORARY',\n",
    "    5: '5. PPD SCH LOSS',\n",
    "    6: '6. PPD NSL',\n",
    "    7: '7. PTD',\n",
    "    8: '8. DEATH'\n",
    "    }\n",
    "\n",
    "def create_submission_df(predictions, test_df):\n",
    "    # Add 1 to predictions to convert back to original scale (0-7 to 1-8)\n",
    "    numeric_predictions = predictions + 1\n",
    "    \n",
    "    # Map numeric predictions to claim type strings\n",
    "    claim_types = [CLAIM_TYPE_MAPPING[pred] for pred in numeric_predictions]\n",
    "    \n",
    "    # Create submission dataframe using original (unscaled) claim identifiers\n",
    "    submission = pd.DataFrame({\n",
    "        'Claim Identifier': test_df['Claim Identifier'].astype(int),  # Original claim IDs\n",
    "        'Claim Injury Type': claim_types  # Full claim type names\n",
    "    })\n",
    "    \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2618697d-11f1-468d-a778-d698c7cac6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission(submission_df, experiment_name):\n",
    "    filename = f'submission_{experiment_name}.csv'\n",
    "    submission_df.to_csv(filename, index=False)\n",
    "    print(f\"\\nSubmission saved to {filename}\")\n",
    "    \n",
    "    # Display sample of submission\n",
    "    print(\"\\nSubmission sample:\")\n",
    "    print(submission_df.head())\n",
    "    print(\"\\nValue counts:\")\n",
    "    print(submission_df['Claim Injury Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee29316-4d05-4b06-bb24-093d74ff1f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = 'Model new'\n",
    "original_claim_ids = test.index.copy()\n",
    "submission_df = create_submission_df(test_pred, pd.DataFrame({'Claim Identifier': original_claim_ids}))\n",
    "save_submission(submission_df, model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf83bd-ad80-4822-b02f-9226a4f11a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96829b7a-5192-44f2-a3af-d67a560655bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
