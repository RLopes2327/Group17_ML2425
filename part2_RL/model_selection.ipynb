{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_data.csv')\n",
    "test = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_index('Claim Identifier', inplace=True)\n",
    "train.drop_duplicates(inplace=True)\n",
    "train.drop('OIICS Nature of Injury Description', axis=1, inplace=True)\n",
    "\n",
    "train.drop(columns=['Birth Year', 'Age at Injury', 'Number of Dependents', 'WCIO Cause of Injury Code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = train.select_dtypes(include=np.number).columns.tolist()\n",
    "train_cat = train.select_dtypes(exclude=np.number).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical columns: Impute with mean\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "train[train_num] = pd.DataFrame(\n",
    "    num_imputer.fit_transform(train[train_num]),\n",
    "    columns=train_num,\n",
    "    index=train.index\n",
    ")\n",
    "\n",
    "# Categorical columns: Impute with most frequent (mode)\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "train[train_cat] = pd.DataFrame(\n",
    "    cat_imputer.fit_transform(train[train_cat]),\n",
    "    columns=train_cat,\n",
    "    index=train.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns='Claim Injury Type')\n",
    "y = train['Claim Injury Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = X.select_dtypes(include=np.number).set_index(X.index)\n",
    "X_cat = X.select_dtypes(exclude=np.number).set_index(X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_num) #fit to training data\n",
    "X_num_scaled = scaler.transform(X_num) # this will return an array\n",
    "X_num_scaled = pd.DataFrame(X_num_scaled, columns = X_num.columns).set_index(X.index) # Convert the array to a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "for col in X_cat.columns:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(X_cat[col].astype(str))\n",
    "    X_cat[col] = le.transform(X_cat[col].astype(str))\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder()\n",
    "y_encoded = ordinal_encoder.fit_transform(y.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = pd.concat([X_num_scaled, X_cat], axis=1)\n",
    "y_encoded_df = pd.DataFrame(y_encoded, columns=['Claim Injury Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_LR(X,y):\n",
    "    model = LogisticRegression().fit(X,y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X,y, model):\n",
    "    y_pred = model.predict(X)\n",
    "    return f1_score(y, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_score_LR(method,X,y):\n",
    "    score_train = []\n",
    "    score_test = []\n",
    "    for train_index, test_index in method.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        model = run_model_LR(X_train, y_train)\n",
    "        value_train = evaluate_model(X_train, y_train, model)\n",
    "        value_test = evaluate_model(X_test,y_test, model)\n",
    "        score_train.append(value_train)\n",
    "        score_test.append(value_test)\n",
    "\n",
    "    print('Train:', np.mean(score_train))\n",
    "    print('Test:', np.mean(score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10) #if the splits are too many, poor efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.10491548496550632\n",
      "Test: 0.09816413934303775\n"
     ]
    }
   ],
   "source": [
    "avg_score_LR(kf, X_combined, y_encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.10389641879963367\n",
      "Test: 0.10390441940548605\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits=6, n_repeats=2)\n",
    "avg_score_LR(rkf, X_combined, y_encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' loo = LeaveOneOut()\\navg_score_LR(loo, X_combined, y_encoded_df) '"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" loo = LeaveOneOut()\n",
    "avg_score_LR(loo, X_combined, y_encoded_df) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_DT(X,y):\n",
    "    model = DecisionTreeClassifier().fit(X,y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_DT(X,y, model):\n",
    "    y_pred = model.predict(X)\n",
    "    return f1_score(y, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO IT\n",
    "def avg_score_DT(method,X,y):\n",
    "    score_train = []\n",
    "    score_test = []\n",
    "    for train_index, test_index in method.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        model = run_model_DT(X_train, y_train)\n",
    "        value_train = evaluate_model_DT(X_train, y_train, model)\n",
    "        value_test = evaluate_model_DT(X_test,y_test, model)\n",
    "        score_train.append(value_train)\n",
    "        score_test.append(value_test)\n",
    "\n",
    "    print('Train:', np.mean(score_train))\n",
    "    print('Test:', np.mean(score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9999715872424831\n",
      "Test: 0.3564713888449257\n"
     ]
    }
   ],
   "source": [
    "kf2 = KFold(n_splits=10) #if the splits are too many, poor efficiency\n",
    "avg_score_DT(kf2, X_combined, y_encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9999761794181835\n",
      "Test: 0.3867963587253302\n"
     ]
    }
   ],
   "source": [
    "rkf2 = RepeatedKFold(n_splits=6, n_repeats=2)\n",
    "avg_score_DT(rkf2, X_combined, y_encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' loo2 = LeaveOneOut()\\navg_score_DT(loo2, X_combined, y_encoded_df) '"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" loo2 = LeaveOneOut()\n",
    "avg_score_DT(loo2, X_combined, y_encoded_df) \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
