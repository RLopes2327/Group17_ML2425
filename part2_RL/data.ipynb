{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_data.csv')\n",
    "test = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accident Date</th>\n",
       "      <th>Age at Injury</th>\n",
       "      <th>Alternative Dispute Resolution</th>\n",
       "      <th>Assembly Date</th>\n",
       "      <th>Attorney/Representative</th>\n",
       "      <th>Average Weekly Wage</th>\n",
       "      <th>Birth Year</th>\n",
       "      <th>C-2 Date</th>\n",
       "      <th>C-3 Date</th>\n",
       "      <th>Carrier Name</th>\n",
       "      <th>Carrier Type</th>\n",
       "      <th>Claim Identifier</th>\n",
       "      <th>Claim Injury Type</th>\n",
       "      <th>County of Injury</th>\n",
       "      <th>COVID-19 Indicator</th>\n",
       "      <th>District Name</th>\n",
       "      <th>First Hearing Date</th>\n",
       "      <th>Gender</th>\n",
       "      <th>IME-4 Count</th>\n",
       "      <th>Industry Code</th>\n",
       "      <th>Industry Code Description</th>\n",
       "      <th>Medical Fee Region</th>\n",
       "      <th>OIICS Nature of Injury Description</th>\n",
       "      <th>WCIO Cause of Injury Code</th>\n",
       "      <th>WCIO Cause of Injury Description</th>\n",
       "      <th>WCIO Nature of Injury Code</th>\n",
       "      <th>WCIO Nature of Injury Description</th>\n",
       "      <th>WCIO Part Of Body Code</th>\n",
       "      <th>WCIO Part Of Body Description</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Agreement Reached</th>\n",
       "      <th>WCB Decision</th>\n",
       "      <th>Number of Dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>31.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW HAMPSHIRE INSURANCE CO</td>\n",
       "      <td>1A. PRIVATE</td>\n",
       "      <td>5393875</td>\n",
       "      <td>2. NON-COMP</td>\n",
       "      <td>ST. LAWRENCE</td>\n",
       "      <td>N</td>\n",
       "      <td>SYRACUSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>RETAIL TRADE</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>FROM LIQUID OR GREASE SPILLS</td>\n",
       "      <td>10.0</td>\n",
       "      <td>CONTUSION</td>\n",
       "      <td>62.0</td>\n",
       "      <td>BUTTOCKS</td>\n",
       "      <td>13662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Work Related</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>46.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Y</td>\n",
       "      <td>1745.93</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>ZURICH AMERICAN INSURANCE CO</td>\n",
       "      <td>1A. PRIVATE</td>\n",
       "      <td>5393091</td>\n",
       "      <td>4. TEMPORARY</td>\n",
       "      <td>WYOMING</td>\n",
       "      <td>N</td>\n",
       "      <td>ROCHESTER</td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>F</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>CONSTRUCTION</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.0</td>\n",
       "      <td>REPETITIVE MOTION</td>\n",
       "      <td>49.0</td>\n",
       "      <td>SPRAIN OR TEAR</td>\n",
       "      <td>38.0</td>\n",
       "      <td>SHOULDER(S)</td>\n",
       "      <td>14569</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not Work Related</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-06</td>\n",
       "      <td>40.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>N</td>\n",
       "      <td>1434.80</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INDEMNITY INSURANCE CO OF</td>\n",
       "      <td>1A. PRIVATE</td>\n",
       "      <td>5393889</td>\n",
       "      <td>4. TEMPORARY</td>\n",
       "      <td>ORANGE</td>\n",
       "      <td>N</td>\n",
       "      <td>ALBANY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>ADMINISTRATIVE AND SUPPORT AND WASTE MANAGEMEN...</td>\n",
       "      <td>II</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0</td>\n",
       "      <td>OBJECT BEING LIFTED OR HANDLED</td>\n",
       "      <td>7.0</td>\n",
       "      <td>CONCUSSION</td>\n",
       "      <td>10.0</td>\n",
       "      <td>MULTIPLE HEAD INJURY</td>\n",
       "      <td>12589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Work Related</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>957648180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>61.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STATE INSURANCE FUND</td>\n",
       "      <td>2A. SIF</td>\n",
       "      <td>5393887</td>\n",
       "      <td>2. NON-COMP</td>\n",
       "      <td>DUTCHESS</td>\n",
       "      <td>N</td>\n",
       "      <td>ALBANY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "      <td>HEALTH CARE AND SOCIAL ASSISTANCE</td>\n",
       "      <td>II</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>HAND TOOL, UTENSIL; NOT POWERED</td>\n",
       "      <td>43.0</td>\n",
       "      <td>PUNCTURE</td>\n",
       "      <td>36.0</td>\n",
       "      <td>FINGER(S)</td>\n",
       "      <td>12603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Work Related</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Accident Date  Age at Injury Alternative Dispute Resolution Assembly Date  \\\n",
       "0    2019-12-30           31.0                              N    2020-01-01   \n",
       "1    2019-08-30           46.0                              N    2020-01-01   \n",
       "2    2019-12-06           40.0                              N    2020-01-01   \n",
       "3           NaN            NaN                            NaN    2020-01-01   \n",
       "4    2019-12-30           61.0                              N    2020-01-01   \n",
       "\n",
       "  Attorney/Representative  Average Weekly Wage  Birth Year    C-2 Date  \\\n",
       "0                       N                 0.00      1988.0  2019-12-31   \n",
       "1                       Y              1745.93      1973.0  2020-01-01   \n",
       "2                       N              1434.80      1979.0  2020-01-01   \n",
       "3                     NaN                  NaN         NaN         NaN   \n",
       "4                       N                  NaN      1958.0  2019-12-31   \n",
       "\n",
       "     C-3 Date                  Carrier Name Carrier Type  Claim Identifier  \\\n",
       "0         NaN    NEW HAMPSHIRE INSURANCE CO  1A. PRIVATE           5393875   \n",
       "1  2020-01-14  ZURICH AMERICAN INSURANCE CO  1A. PRIVATE           5393091   \n",
       "2         NaN     INDEMNITY INSURANCE CO OF  1A. PRIVATE           5393889   \n",
       "3         NaN                           NaN          NaN         957648180   \n",
       "4         NaN          STATE INSURANCE FUND      2A. SIF           5393887   \n",
       "\n",
       "  Claim Injury Type County of Injury COVID-19 Indicator District Name  \\\n",
       "0       2. NON-COMP     ST. LAWRENCE                  N      SYRACUSE   \n",
       "1      4. TEMPORARY          WYOMING                  N     ROCHESTER   \n",
       "2      4. TEMPORARY           ORANGE                  N        ALBANY   \n",
       "3               NaN              NaN                NaN           NaN   \n",
       "4       2. NON-COMP         DUTCHESS                  N        ALBANY   \n",
       "\n",
       "  First Hearing Date Gender  IME-4 Count  Industry Code  \\\n",
       "0                NaN      M          NaN           44.0   \n",
       "1         2020-02-21      F          4.0           23.0   \n",
       "2                NaN      M          NaN           56.0   \n",
       "3                NaN    NaN          NaN            NaN   \n",
       "4                NaN      M          NaN           62.0   \n",
       "\n",
       "                           Industry Code Description Medical Fee Region  \\\n",
       "0                                       RETAIL TRADE                  I   \n",
       "1                                       CONSTRUCTION                  I   \n",
       "2  ADMINISTRATIVE AND SUPPORT AND WASTE MANAGEMEN...                 II   \n",
       "3                                                NaN                NaN   \n",
       "4                  HEALTH CARE AND SOCIAL ASSISTANCE                 II   \n",
       "\n",
       "   OIICS Nature of Injury Description  WCIO Cause of Injury Code  \\\n",
       "0                                 NaN                       27.0   \n",
       "1                                 NaN                       97.0   \n",
       "2                                 NaN                       79.0   \n",
       "3                                 NaN                        NaN   \n",
       "4                                 NaN                       16.0   \n",
       "\n",
       "  WCIO Cause of Injury Description  WCIO Nature of Injury Code  \\\n",
       "0     FROM LIQUID OR GREASE SPILLS                        10.0   \n",
       "1                REPETITIVE MOTION                        49.0   \n",
       "2   OBJECT BEING LIFTED OR HANDLED                         7.0   \n",
       "3                              NaN                         NaN   \n",
       "4  HAND TOOL, UTENSIL; NOT POWERED                        43.0   \n",
       "\n",
       "  WCIO Nature of Injury Description  WCIO Part Of Body Code  \\\n",
       "0                         CONTUSION                    62.0   \n",
       "1                    SPRAIN OR TEAR                    38.0   \n",
       "2                        CONCUSSION                    10.0   \n",
       "3                               NaN                     NaN   \n",
       "4                          PUNCTURE                    36.0   \n",
       "\n",
       "  WCIO Part Of Body Description Zip Code  Agreement Reached      WCB Decision  \\\n",
       "0                      BUTTOCKS    13662                0.0  Not Work Related   \n",
       "1                   SHOULDER(S)    14569                1.0  Not Work Related   \n",
       "2          MULTIPLE HEAD INJURY    12589                0.0  Not Work Related   \n",
       "3                           NaN      NaN                NaN               NaN   \n",
       "4                     FINGER(S)    12603                0.0  Not Work Related   \n",
       "\n",
       "   Number of Dependents  \n",
       "0                   1.0  \n",
       "1                   4.0  \n",
       "2                   6.0  \n",
       "3                   NaN  \n",
       "4                   1.0  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accident Date</th>\n",
       "      <th>Age at Injury</th>\n",
       "      <th>Alternative Dispute Resolution</th>\n",
       "      <th>Assembly Date</th>\n",
       "      <th>Attorney/Representative</th>\n",
       "      <th>Average Weekly Wage</th>\n",
       "      <th>Birth Year</th>\n",
       "      <th>C-2 Date</th>\n",
       "      <th>C-3 Date</th>\n",
       "      <th>Carrier Name</th>\n",
       "      <th>Carrier Type</th>\n",
       "      <th>Claim Identifier</th>\n",
       "      <th>County of Injury</th>\n",
       "      <th>COVID-19 Indicator</th>\n",
       "      <th>District Name</th>\n",
       "      <th>First Hearing Date</th>\n",
       "      <th>Gender</th>\n",
       "      <th>IME-4 Count</th>\n",
       "      <th>Industry Code</th>\n",
       "      <th>Industry Code Description</th>\n",
       "      <th>Medical Fee Region</th>\n",
       "      <th>OIICS Nature of Injury Description</th>\n",
       "      <th>WCIO Cause of Injury Code</th>\n",
       "      <th>WCIO Cause of Injury Description</th>\n",
       "      <th>WCIO Nature of Injury Code</th>\n",
       "      <th>WCIO Nature of Injury Description</th>\n",
       "      <th>WCIO Part Of Body Code</th>\n",
       "      <th>WCIO Part Of Body Description</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Number of Dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-24</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INDEMNITY INSURANCE CO OF</td>\n",
       "      <td>1A. PRIVATE</td>\n",
       "      <td>6165911</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>N</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>TRANSPORTATION AND WAREHOUSING</td>\n",
       "      <td>IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>FALL, SLIP OR TRIP, NOC</td>\n",
       "      <td>10.0</td>\n",
       "      <td>CONTUSION</td>\n",
       "      <td>54.0</td>\n",
       "      <td>LOWER LEG</td>\n",
       "      <td>10466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-20</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A I U INSURANCE COMPANY</td>\n",
       "      <td>1A. PRIVATE</td>\n",
       "      <td>6166141</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>N</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>RETAIL TRADE</td>\n",
       "      <td>IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>FALLING OR FLYING OBJECT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>CONTUSION</td>\n",
       "      <td>10.0</td>\n",
       "      <td>MULTIPLE HEAD INJURY</td>\n",
       "      <td>11691</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>59</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AMGUARD INSURANCE COMPANY</td>\n",
       "      <td>1A. PRIVATE</td>\n",
       "      <td>6165907</td>\n",
       "      <td>WESTCHESTER</td>\n",
       "      <td>N</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>ADMINISTRATIVE AND SUPPORT AND WASTE MANAGEMEN...</td>\n",
       "      <td>III</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>STATIONARY OBJECT</td>\n",
       "      <td>49.0</td>\n",
       "      <td>SPRAIN OR TEAR</td>\n",
       "      <td>62.0</td>\n",
       "      <td>BUTTOCKS</td>\n",
       "      <td>10604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>55</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INDEMNITY INS. OF N AMERICA</td>\n",
       "      <td>1A. PRIVATE</td>\n",
       "      <td>6166047</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>N</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>TRANSPORTATION AND WAREHOUSING</td>\n",
       "      <td>IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>FROM DIFFERENT LEVEL (ELEVATION)</td>\n",
       "      <td>10.0</td>\n",
       "      <td>CONTUSION</td>\n",
       "      <td>53.0</td>\n",
       "      <td>KNEE</td>\n",
       "      <td>11411</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-20</td>\n",
       "      <td>25</td>\n",
       "      <td>N</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW HAMPSHIRE INSURANCE CO</td>\n",
       "      <td>1A. PRIVATE</td>\n",
       "      <td>6166102</td>\n",
       "      <td>KINGS</td>\n",
       "      <td>N</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>MANAGEMENT OF COMPANIES AND ENTERPRISES</td>\n",
       "      <td>IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0</td>\n",
       "      <td>OBJECT BEING LIFTED OR HANDLED</td>\n",
       "      <td>40.0</td>\n",
       "      <td>LACERATION</td>\n",
       "      <td>37.0</td>\n",
       "      <td>THUMB</td>\n",
       "      <td>11212</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Accident Date  Age at Injury Alternative Dispute Resolution Assembly Date  \\\n",
       "0    2022-12-24             19                              N    2023-01-02   \n",
       "1    2022-11-20             19                              N    2023-01-02   \n",
       "2    2022-12-26             59                              N    2023-01-02   \n",
       "3    2022-12-28             55                              N    2023-01-02   \n",
       "4    2022-12-20             25                              N    2023-01-02   \n",
       "\n",
       "  Attorney/Representative  Average Weekly Wage  Birth Year    C-2 Date  \\\n",
       "0                       N                  NaN      2003.0  2023-01-02   \n",
       "1                       N                  NaN      2003.0  2023-01-02   \n",
       "2                       N                  0.0      1963.0  2022-12-31   \n",
       "3                       N                  0.0         0.0  2023-01-02   \n",
       "4                       N                  0.0      1997.0  2022-12-31   \n",
       "\n",
       "  C-3 Date                 Carrier Name Carrier Type  Claim Identifier  \\\n",
       "0      NaN    INDEMNITY INSURANCE CO OF  1A. PRIVATE           6165911   \n",
       "1      NaN      A I U INSURANCE COMPANY  1A. PRIVATE           6166141   \n",
       "2      NaN    AMGUARD INSURANCE COMPANY  1A. PRIVATE           6165907   \n",
       "3      NaN  INDEMNITY INS. OF N AMERICA  1A. PRIVATE           6166047   \n",
       "4      NaN   NEW HAMPSHIRE INSURANCE CO  1A. PRIVATE           6166102   \n",
       "\n",
       "  County of Injury COVID-19 Indicator District Name First Hearing Date Gender  \\\n",
       "0            BRONX                  N           NYC                NaN      M   \n",
       "1           QUEENS                  N           NYC                NaN      F   \n",
       "2      WESTCHESTER                  N           NYC                NaN      F   \n",
       "3           QUEENS                  N           NYC                NaN      F   \n",
       "4            KINGS                  N           NYC                NaN      M   \n",
       "\n",
       "   IME-4 Count  Industry Code  \\\n",
       "0          NaN           48.0   \n",
       "1          NaN           45.0   \n",
       "2          NaN           56.0   \n",
       "3          NaN           48.0   \n",
       "4          NaN           55.0   \n",
       "\n",
       "                           Industry Code Description Medical Fee Region  \\\n",
       "0                     TRANSPORTATION AND WAREHOUSING                 IV   \n",
       "1                                       RETAIL TRADE                 IV   \n",
       "2  ADMINISTRATIVE AND SUPPORT AND WASTE MANAGEMEN...                III   \n",
       "3                     TRANSPORTATION AND WAREHOUSING                 IV   \n",
       "4            MANAGEMENT OF COMPANIES AND ENTERPRISES                 IV   \n",
       "\n",
       "   OIICS Nature of Injury Description  WCIO Cause of Injury Code  \\\n",
       "0                                 NaN                       31.0   \n",
       "1                                 NaN                       75.0   \n",
       "2                                 NaN                       68.0   \n",
       "3                                 NaN                       25.0   \n",
       "4                                 NaN                       79.0   \n",
       "\n",
       "   WCIO Cause of Injury Description  WCIO Nature of Injury Code  \\\n",
       "0           FALL, SLIP OR TRIP, NOC                        10.0   \n",
       "1          FALLING OR FLYING OBJECT                        10.0   \n",
       "2                 STATIONARY OBJECT                        49.0   \n",
       "3  FROM DIFFERENT LEVEL (ELEVATION)                        10.0   \n",
       "4    OBJECT BEING LIFTED OR HANDLED                        40.0   \n",
       "\n",
       "  WCIO Nature of Injury Description  WCIO Part Of Body Code  \\\n",
       "0                         CONTUSION                    54.0   \n",
       "1                         CONTUSION                    10.0   \n",
       "2                    SPRAIN OR TEAR                    62.0   \n",
       "3                         CONTUSION                    53.0   \n",
       "4                        LACERATION                    37.0   \n",
       "\n",
       "  WCIO Part Of Body Description Zip Code  Number of Dependents  \n",
       "0                     LOWER LEG    10466                     1  \n",
       "1          MULTIPLE HEAD INJURY    11691                     1  \n",
       "2                      BUTTOCKS    10604                     0  \n",
       "3                          KNEE    11411                     6  \n",
       "4                         THUMB    11212                     5  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_index('Claim Identifier', inplace=True)\n",
    "test.set_index('Claim Identifier', inplace=True)\n",
    "train.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(subset=['Claim Injury Type'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "column with all nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['OIICS Nature of Injury Description', 'WCB Decision', 'Carrier Name'], inplace=True)\n",
    "test.drop(columns=['OIICS Nature of Injury Description', 'Carrier Name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['WCIO Part Of Body Code'] = train['WCIO Part Of Body Code'].apply(lambda x: 0 if x < 0 else x)\n",
    "test['WCIO Part Of Body Code'] = test['WCIO Part Of Body Code'].apply(lambda x: 0 if x < 0 else x)\n",
    "## IN DATE\n",
    "date_cols = ['Accident Date', 'Assembly Date', 'C-2 Date', 'C-3 Date', 'First Hearing Date'] \n",
    "for col in date_cols:\n",
    "    # Convert to datetime\n",
    "    train[col] = pd.to_datetime(train[col], errors='coerce')\n",
    "    test[col] = pd.to_datetime(test[col], errors='coerce')\n",
    "    \n",
    "    # Extract year, month, and day\n",
    "    train[f'{col}_Year'] = train[col].dt.year\n",
    "    train[f'{col}_Month'] = train[col].dt.month\n",
    "    train[f'{col}_Day'] = train[col].dt.day\n",
    "    \n",
    "    test[f'{col}_Year'] = test[col].dt.year\n",
    "    test[f'{col}_Month'] = test[col].dt.month\n",
    "    test[f'{col}_Day'] = test[col].dt.day\n",
    "train.drop(columns=date_cols, inplace=True)\n",
    "test.drop(columns=date_cols, inplace=True)\n",
    "    \n",
    "# IN INT\n",
    "def to_int(train):\n",
    "    int_cols = ['Age at Injury', 'Birth Year', 'IME-4 Count', 'Number of Dependents']\n",
    "    for col in int_cols:\n",
    "        train[col] = train[col].astype('int64')\n",
    "    return train\n",
    "\n",
    "# IN OBJECT\n",
    "float_to_object = ['Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code']\n",
    "train[float_to_object] = train[float_to_object].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiy them as Non-US residents\n",
    "train['Zip Code'] = train['Zip Code'].apply(\n",
    "    lambda x: x[:2] if isinstance(x, str) and len(x) == 5 and x.isdigit() else ('Non-US Resident' if pd.notna(x) else np.nan)\n",
    ")\n",
    "test['Zip Code'] = test['Zip Code'].apply(\n",
    "    lambda x: x[:2] if isinstance(x, str) and len(x) == 5 and x.isdigit() else ('Non-US Resident' if pd.notna(x) else np.nan)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip Code\n",
      "NY Resident            503921\n",
      "non-NY US Residents     26093\n",
      "Non-US Resident         15374\n",
      "Name: count, dtype: int64\n",
      "\n",
      "NaN: 28637\n"
     ]
    }
   ],
   "source": [
    "#zip codes that start with 1 come from NY state - where the data set is based\n",
    "# we decide to divide those that are from NY from those that even though are US residents, are not from NY\n",
    "train['Zip Code'] = np.where(\n",
    "    (train['Zip Code'] != 'Unknown') & \n",
    "    (train['Zip Code'] != 'Non-US Resident') & \n",
    "    train['Zip Code'].notna() & \n",
    "    train['Zip Code'].str.startswith('1'), \n",
    "    'NY Resident', \n",
    "    np.where(\n",
    "        (train['Zip Code'] != 'Unknown') & \n",
    "        (train['Zip Code'] != 'Non-US Resident') & \n",
    "        train['Zip Code'].notna(), \n",
    "        'non-NY US Residents', \n",
    "        train['Zip Code']\n",
    "    )\n",
    ")\n",
    "test['Zip Code'] = np.where(\n",
    "    (test['Zip Code'] != 'Unknown') & \n",
    "    (test['Zip Code'] != 'Non-US Resident') & \n",
    "    test['Zip Code'].notna() & \n",
    "    test['Zip Code'].str.startswith('1'), \n",
    "    'NY Resident', \n",
    "    np.where(\n",
    "        (test['Zip Code'] != 'Unknown') & \n",
    "        (test['Zip Code'] != 'Non-US Resident') & \n",
    "        test['Zip Code'].notna(), \n",
    "        'non-NY US Residents', \n",
    "        test['Zip Code']\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(train['Zip Code'].value_counts())\n",
    "print() \n",
    "print('NaN:', train['Zip Code'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, method=None):\n",
    "    splits = []\n",
    "    if method is None:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, \n",
    "                                                random_state = 0, \n",
    "                                                stratify = y, \n",
    "                                                shuffle = True)\n",
    "        splits.append((X_train, X_test, y_train, y_test))\n",
    "    elif isinstance(method, StratifiedKFold):\n",
    "        for train_index, test_index in method.split(X, y):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            splits.append((X_train, X_test, y_train, y_test))\n",
    "    else:\n",
    "        for train_index, test_index in method.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            splits.append((X_train, X_test, y_train, y_test))\n",
    "\n",
    "    processed_splits = []\n",
    "    for X_train, X_test, y_train, y_test in splits:\n",
    "        X_train_num = X_train.select_dtypes(include=np.number)\n",
    "        X_test_num = X_test.select_dtypes(include=np.number)\n",
    "        X_train_cat = X_train.select_dtypes(exclude=np.number)\n",
    "        X_test_cat = X_test.select_dtypes(exclude=np.number)\n",
    "        processed_splits.append((X_train_num, X_test_num, X_train_cat, X_test_cat, y_train, y_test))\n",
    "\n",
    "    return processed_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputing(X_train_num, X_test_num, X_train_cat, X_test_cat):\n",
    "    #Using median for numerical data\n",
    "    num_imputer = SimpleImputer(strategy=\"median\")\n",
    "    X_train_num = pd.DataFrame(num_imputer.fit_transform(X_train_num), columns=X_train_num.columns)\n",
    "    X_test_num = pd.DataFrame(num_imputer.transform(X_test_num), columns=X_test_num.columns)\n",
    "\n",
    "    #Using most frequent for categorical data\n",
    "    cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    X_train_cat = pd.DataFrame(cat_imputer.fit_transform(X_train_cat), columns=X_train_cat.columns)\n",
    "    X_test_cat = pd.DataFrame(cat_imputer.transform(X_test_cat), columns=X_test_cat.columns)\n",
    "\n",
    "    return X_train_num, X_test_num, X_train_cat, X_test_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate IQR and identify outliers for a specific column\n",
    "def identify_outliers_iqr_column(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = (df[column] < lower_bound) | (df[column] > upper_bound)\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers(X_train_num, y_train):\n",
    "    not_voluntary = X_train_num['Average Weekly Wage'] != 0\n",
    "    not_voluntary_df = X_train_num[not_voluntary]\n",
    "    \n",
    "    outliers_mask = identify_outliers_iqr_column(not_voluntary_df, 'Average Weekly Wage')\n",
    "    outliers_indices = not_voluntary_df[outliers_mask].index\n",
    "\n",
    "    X_train_num = X_train_num.drop(index=outliers_indices, errors='ignore')\n",
    "    y_train = y_train.drop(index=outliers_indices, errors='ignore')\n",
    "    \n",
    "    return X_train_num, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(X_train, X_test, scaler):\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns).set_index(X_train.index)\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns).set_index(X_test.index)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if var == 0 then drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(X_train, threshold, return_variances=False):\n",
    "    variances = X_train.var()\n",
    "    low_variance_cols = variances[variances == threshold].index.tolist()\n",
    "    if return_variances:\n",
    "        return low_variance_cols, variances.to_dict()\n",
    "    return low_variance_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spearman correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_correlated_vars(X_train, threshold):\n",
    "    cor_spearman = X_train.corr(method='spearman')\n",
    "    correlated_pairs = []\n",
    "    for i in range(len(cor_spearman.columns)):\n",
    "        for j in range(i):\n",
    "            correlation = cor_spearman.iloc[i, j]\n",
    "            if abs(correlation) >= threshold:\n",
    "                correlated_pairs.append({\n",
    "                    \"feature_1\": cor_spearman.columns[i],\n",
    "                    \"feature_2\": cor_spearman.columns[j],\n",
    "                    \"correlation\": correlation\n",
    "                })\n",
    "    return correlated_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chi square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_independence(x,y,alpha=0.05):        \n",
    "    dfObserved = pd.crosstab(y,x) \n",
    "    if dfObserved.empty:\n",
    "        print(f\"Skipping column {x.name} due to empty observed table.\")\n",
    "        return None\n",
    "    if x.nunique() <= 1:\n",
    "        print(f\"Skipping column {x.name} as it has <= 1 unique value.\")\n",
    "        return None\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(dfObserved.values)\n",
    "    is_important = p < alpha\n",
    "    result = {\n",
    "        \"feature\": x.name,\n",
    "        \"p_value\": p,\n",
    "        \"chi2_stat\": chi2,\n",
    "        \"is_important\": is_important\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square(X_train, y, alpha=0.05):\n",
    "    if X_train.empty or y.empty:\n",
    "        raise ValueError(\"X_train or y is empty.\")\n",
    "    if len(y.unique()) < 2:\n",
    "        raise ValueError(\"y must have at least two unique classes.\")\n",
    "    results = []\n",
    "    for var in X_train.columns:\n",
    "        test_result = test_independence(X_train[var], y, alpha)\n",
    "        if test_result is None:\n",
    "            print(\"Deu none\")\n",
    "        results.append(test_result)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    not_important_features = results_df[~results_df[\"is_important\"]][\"feature\"].tolist()\n",
    "    \n",
    "    return results_df, not_important_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relation with the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bar_charts_categorical(df, feature, target):\n",
    "#     cont_tab = pd.crosstab(df[feature], df[target], margins=True)\n",
    "#     categories = cont_tab.index[:-1]\n",
    "#     target_categories = cont_tab.columns[:-1]\n",
    "    \n",
    "#     fig = plt.figure(figsize=(15, 5))\n",
    "    \n",
    "#     plt.subplot(121)\n",
    "#     bottom = np.zeros(len(categories))\n",
    "#     colors = plt.cm.tab20.colors  # Use a colormap for different colors\n",
    "#     bars = []\n",
    "#     for i, target_cat in enumerate(target_categories):\n",
    "#         bar = plt.bar(categories, cont_tab.iloc[:-1, i].values, 0.55, bottom=bottom, color=colors[i % len(colors)])\n",
    "#         bars.append(bar[0])\n",
    "#         bottom += cont_tab.iloc[:-1, i].values\n",
    "#     plt.legend(bars, [f'$y_i={cat}$' for cat in target_categories])\n",
    "#     plt.title(\"Frequency bar chart\")\n",
    "#     plt.xlabel(feature)\n",
    "#     plt.ylabel(\"$Frequency$\")\n",
    "\n",
    "#     # auxiliary data for 122\n",
    "#     obs_pct = np.array([np.divide(cont_tab.iloc[:-1, i].values, cont_tab.iloc[:-1, -1].values) for i in range(len(target_categories))])\n",
    "    \n",
    "#     plt.subplot(122)\n",
    "#     bottom = np.zeros(len(categories))\n",
    "#     bars = []\n",
    "#     for i, target_cat in enumerate(target_categories):\n",
    "#         bar = plt.bar(categories, obs_pct[i], 0.55, bottom=bottom, color=colors[i % len(colors)])\n",
    "#         bars.append(bar[0])\n",
    "#         bottom += obs_pct[i]\n",
    "#     plt.legend(bars, [f'$y_i={cat}$' for cat in target_categories])\n",
    "#     plt.title(\"Proportion bar chart\")\n",
    "#     plt.xlabel(feature)\n",
    "#     plt.ylabel(\"$p$\")\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "# def plot_and_test_correlation(df, target):\n",
    "#     for feature in df.select_dtypes(include='object').columns:\n",
    "#         print(f\"Generating bar charts for {feature}...\")\n",
    "#         bar_charts_categorical(df, feature, target)\n",
    "\n",
    "# plot_and_test_correlation(train, 'Claim Injury Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_optimal_features_rfe(X_train, y_train, X_val, y_val, model, scoring_function=None):\n",
    "    if scoring_function is None:\n",
    "        scoring_function = lambda model, X, y: model.score(X, y)\n",
    "\n",
    "    nof_list=np.arange(1, X_train.shape[1]+1)\n",
    "    high_score = 0\n",
    "    nof = 0\n",
    "    train_score_list = []\n",
    "    val_score_list = []\n",
    "\n",
    "    for n in nof_list:\n",
    "        rfe = RFE(estimator=model, n_features_to_select=n)\n",
    "        X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "        X_val_rfe = rfe.transform(X_val)\n",
    "        model.fit(X_train_rfe, y_train)\n",
    "\n",
    "        # Storing results on training data\n",
    "        train_score = scoring_function(model, X_train_rfe, y_train)\n",
    "        train_score_list.append(train_score)\n",
    "\n",
    "        # Storing results on validation data\n",
    "        val_score = scoring_function(model, X_val_rfe, y_val)\n",
    "        val_score_list.append(val_score)\n",
    "\n",
    "        # Check best score\n",
    "        if val_score >= high_score:\n",
    "            high_score = val_score\n",
    "            nof = n\n",
    "\n",
    "    # Fit RFE with the optimal number of features\n",
    "    rfe = RFE(estimator=model, n_features_to_select=nof)\n",
    "    rfe.fit(X_train, y_train)\n",
    "    selected_features = X_train.columns[rfe.support_].tolist()\n",
    "\n",
    "    return selected_features, train_score_list, val_score_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedded methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_features_embedded(X_train, y_train, model, threshold=None):\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the coefficients or feature importances\n",
    "    if hasattr(model, 'coef_'):\n",
    "        if model.coef_.ndim > 1:\n",
    "            coef = pd.Series(model.coef_.mean(axis=0), index=X_train.columns)\n",
    "        else:\n",
    "            coef = pd.Series(model.coef_, index=X_train.columns)\n",
    "    elif hasattr(model, 'feature_importances_'):\n",
    "        coef = pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "    else:\n",
    "        raise ValueError(\"The model does not have coef_ or feature_importances_ attributes\")\n",
    "    \n",
    "    if threshold is not None:\n",
    "        selected_features = coef[coef.abs() > threshold].index.tolist()\n",
    "    else:\n",
    "        selected_features = coef[coef != 0].index.tolist()\n",
    "    \n",
    "    return selected_features, coef[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_cardinality(df, threshold=10, other_label='Other'):\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        value_counts = df[col].value_counts()\n",
    "        frequent_values = value_counts[value_counts > threshold].index\n",
    "        df[col] = df[col].apply(lambda x: x if x in frequent_values else other_label)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_independent(X_train, X_test, encoder):\n",
    "    X_train = X_train.astype(str)\n",
    "    X_test = X_test.astype(str)\n",
    "    \n",
    "    encoder.fit(X_train)\n",
    "    X_train_encoded = encoder.transform(X_train) \n",
    "    X_test_encoded = encoder.transform(X_test)\n",
    "\n",
    "    if isinstance(encoder, OneHotEncoder):\n",
    "        feature_names = encoder.get_feature_names_out(X_train.columns)\n",
    "        X_train_encoded = pd.DataFrame(X_train_encoded, columns=feature_names, index=X_train.index)\n",
    "        X_test_encoded = pd.DataFrame(X_test_encoded, columns=feature_names, index=X_test.index)\n",
    "    else:\n",
    "        X_train_encoded = pd.DataFrame(X_train_encoded, columns=X_train.columns, index=X_train.index)\n",
    "        X_test_encoded = pd.DataFrame(X_test_encoded, columns=X_test.columns, index=X_test.index)\n",
    "    \n",
    "    return X_train_encoded, X_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_dependent(y_train, y_test, encoder):\n",
    "    encoder.fit(y_train)\n",
    "    y_train_encoded = pd.Series(encoder.transform(y_train))\n",
    "    y_test_encoded = pd.Series(encoder.transform(y_test))\n",
    "\n",
    "    return y_train_encoded, y_test_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(X, y, method='oversample'):\n",
    "    if method == 'oversample':\n",
    "        sampler = RandomOverSampler(random_state=42)\n",
    "    elif method == 'undersample':\n",
    "        sampler = RandomUnderSampler(random_state=42)\n",
    "    elif method == 'smote':\n",
    "        sampler = SMOTEENN(random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Method should be 'oversample', 'undersample', or 'smote'\")\n",
    "    \n",
    "    X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(X_train, X_test, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    pca_feat_names = [f'PC{i}' for i in range(n_components)]\n",
    "\n",
    "    X_train_pca = pd.DataFrame(X_train_pca, index=X_train.index, columns=pca_feat_names)\n",
    "    X_test_pca = pd.DataFrame(X_test_pca, index=X_test.index, columns=pca_feat_names)\n",
    "    \n",
    "    return X_train_pca, X_test_pca, pca_feat_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling and Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X,y, model):\n",
    "    return model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def evaluate_model(X, y, model, is_classification=True):\n",
    "    predictions = model.predict(X)\n",
    "    if is_classification:\n",
    "        return classification_report(y, predictions)\n",
    "    else:\n",
    "        mse = mean_squared_error(y, predictions)\n",
    "        r2 = r2_score(y, predictions)\n",
    "        return {\n",
    "            'mean_squared_error': mse,\n",
    "            'r2_score': r2\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' def pipeline(X, y, method, scaler, encoder_independent, encoder_dependent, model): #, balance_method\\n    splits = split_data(X, y, method)\\n    print(\"Split data OK.\")\\n\\n    # Initialize results storage for each split\\n    results = {}\\n\\n    for i, (X_train_num, X_test_num, X_train_cat, X_test_cat, y_train, y_test) in enumerate(splits):\\n        X_train_num, X_test_num, X_train_cat, X_test_cat = imputing(X_train_num, X_test_num, X_train_cat, X_test_cat)\\n        print(f\"Imputing OK for split {i + 1}.\")\\n\\n        X_train_num = to_int(X_train_num)\\n        X_test_num = to_int(X_test_num)\\n        \\n        # X_train_num, y_train = outliers(X_train_num, y_train)\\n        \\n        X_train_num_scaled, X_test_num_scaled = scaling(X_train_num, X_test_num, scaler)\\n        print(f\"Scaling OK for split {i + 1}.\")\\n    \\n        # unique_counts = X_train_cat.nunique()\\n        # X_train_cat.drop(columns=unique_counts[unique_counts == 1].index, inplace=True)\\n        # X_test_cat.drop(columns=unique_counts[unique_counts == 1].index, inplace=True)\\n\\n        X_train_cat = reduce_cardinality(X_train_cat)\\n        X_test_cat = reduce_cardinality(X_test_cat)\\n        print(f\"Reducing cardinality OK for split {i + 1}.\")\\n        \\n        X_train_cat_encoded, X_test_cat_encoded = encoding_independent(X_train_cat, X_test_cat, encoder_independent)\\n        print(f\"Encoding independent OK for split {i + 1}.\")\\n        \\n        y_train_encoded, y_test_encoded = encoding_dependent(y_train, y_test, encoder_dependent)\\n        print(f\"Encoding dependent OK for split {i + 1}.\")\\n        \\n        X_train = pd.concat([X_train_num_scaled, X_train_cat_encoded], axis=1)\\n        X_test = pd.concat([X_test_num_scaled, X_test_cat_encoded], axis=1)\\n        print(f\"Concatenating OK for split {i + 1}.\")\\n\\n        # if balance_method in [\\'oversample\\', \\'undersample\\', \\'smote\\']:\\n        #     X_train, y_train_encoded = balance_data(X_train, y_train_encoded, method=balance_method)\\n        #     print(f\"Balancing OK for split {i + 1}.\")\\n        \\n        model = run_model(X_train, y_train_encoded, model)\\n        print(f\"Model fitted OK for split {i + 1}.\")\\n\\n        is_classification = not isinstance(model, LassoCV)\\n        \\n        results[f\"split_{i + 1}\"] = evaluate_model(X_test, y_test_encoded, model, is_classification)\\n        print(f\"Evaluation OK for split {i + 1}.\")\\n        \\n    \\n    return results '"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" def pipeline(X, y, method, scaler, encoder_independent, encoder_dependent, model): #, balance_method\n",
    "    splits = split_data(X, y, method)\n",
    "    print(\"Split data OK.\")\n",
    "\n",
    "    # Initialize results storage for each split\n",
    "    results = {}\n",
    "\n",
    "    for i, (X_train_num, X_test_num, X_train_cat, X_test_cat, y_train, y_test) in enumerate(splits):\n",
    "        X_train_num, X_test_num, X_train_cat, X_test_cat = imputing(X_train_num, X_test_num, X_train_cat, X_test_cat)\n",
    "        print(f\"Imputing OK for split {i + 1}.\")\n",
    "\n",
    "        X_train_num = to_int(X_train_num)\n",
    "        X_test_num = to_int(X_test_num)\n",
    "        \n",
    "        # X_train_num, y_train = outliers(X_train_num, y_train)\n",
    "        \n",
    "        X_train_num_scaled, X_test_num_scaled = scaling(X_train_num, X_test_num, scaler)\n",
    "        print(f\"Scaling OK for split {i + 1}.\")\n",
    "    \n",
    "        # unique_counts = X_train_cat.nunique()\n",
    "        # X_train_cat.drop(columns=unique_counts[unique_counts == 1].index, inplace=True)\n",
    "        # X_test_cat.drop(columns=unique_counts[unique_counts == 1].index, inplace=True)\n",
    "\n",
    "        X_train_cat = reduce_cardinality(X_train_cat)\n",
    "        X_test_cat = reduce_cardinality(X_test_cat)\n",
    "        print(f\"Reducing cardinality OK for split {i + 1}.\")\n",
    "        \n",
    "        X_train_cat_encoded, X_test_cat_encoded = encoding_independent(X_train_cat, X_test_cat, encoder_independent)\n",
    "        print(f\"Encoding independent OK for split {i + 1}.\")\n",
    "        \n",
    "        y_train_encoded, y_test_encoded = encoding_dependent(y_train, y_test, encoder_dependent)\n",
    "        print(f\"Encoding dependent OK for split {i + 1}.\")\n",
    "        \n",
    "        X_train = pd.concat([X_train_num_scaled, X_train_cat_encoded], axis=1)\n",
    "        X_test = pd.concat([X_test_num_scaled, X_test_cat_encoded], axis=1)\n",
    "        print(f\"Concatenating OK for split {i + 1}.\")\n",
    "\n",
    "        # if balance_method in ['oversample', 'undersample', 'smote']:\n",
    "        #     X_train, y_train_encoded = balance_data(X_train, y_train_encoded, method=balance_method)\n",
    "        #     print(f\"Balancing OK for split {i + 1}.\")\n",
    "        \n",
    "        model = run_model(X_train, y_train_encoded, model)\n",
    "        print(f\"Model fitted OK for split {i + 1}.\")\n",
    "\n",
    "        is_classification = not isinstance(model, LassoCV)\n",
    "        \n",
    "        results[f\"split_{i + 1}\"] = evaluate_model(X_test, y_test_encoded, model, is_classification)\n",
    "        print(f\"Evaluation OK for split {i + 1}.\")\n",
    "        \n",
    "    \n",
    "    return results \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' X = train.drop(\\'Claim Injury Type\\', axis=1)\\ny = train[\\'Claim Injury Type\\']\\n\\n# Define configurations\\ncv_methods = [None] #, KFold(n_splits=10), RepeatedKFold(n_splits=6, n_repeats=2), StratifiedKFold(n_splits=10)\\nscalers = [StandardScaler()] #, MinMaxScaler()\\nencoders = [OneHotEncoder(sparse_output=False, drop=\"first\", handle_unknown=\\'ignore\\')] # , OrdinalEncoder(handle_unknown=\\'use_encoded_value\\', unknown_value=-1)\\n#balance_methods = [\\'oversample\\', \\'undersample\\', \\'smote\\']\\nmodels = [\\n    (\"DecisionTree\", DecisionTreeClassifier()),\\n    (\"LogisticRegression\", LogisticRegression(class_weight=\\'balanced\\', max_iter=1000)),\\n    (\"Lasso\", LassoCV())\\n]\\n\\n# Results storage\\nresults = []\\n\\n# Iterate through combinations\\nfor scaler in scalers:\\n    for encoder in encoders:\\n        for model_name, model in models:\\n            for cv_method in cv_methods:\\n                #for balance_method in balance_methods:\\n                    if model_name in [\"LogisticRegression\", \"Lasso\"] and isinstance(encoder, OrdinalEncoder):\\n                        continue  # Skip OrdinalEncoder for LogisticRegression and Lasso\\n                    # if model_name == \"LogisticRegression\":\\n                    #     balance_method = None  # LogisticRegression does not need balancing\\n                    \\n                    # Apply pipeline steps (e.g., split, scale, encode, model)\\n                    try:\\n                        pipeline_result = pipeline(X, y, cv_method, scaler, encoder, LabelEncoder(), model) #, balance_method\\n                        results.append({\\n                            \"scaler\": scaler.__class__.__name__,\\n                            \"encoder\": encoder.__class__.__name__,\\n                            \"model\": model_name,\\n                            \"cv_method\": \"TrainTestSplit\" if cv_method is None else cv_method.__class__.__name__,\\n                            #\"balance_method\": balance_method if balance_method else \\'none\\',\\n                            \"results\": pipeline_result\\n                        })\\n                        print(\"========================================\")\\n                        print(f\"Scaler: {scaler.__class__.__name__}\")\\n                        print(f\"Encoder: {encoder.__class__.__name__}\")\\n                        print(f\"Model: {model_name}\")\\n                        print(f\"Cross-Validation Method: {\\'TrainTestSplit\\' if cv_method is None else cv_method.__class__.__name__}\")\\n                        #print(f\"Balancing Method: {balance_method if balance_method else \\'none\\'}\")\\n                        print(\"Results:\")\\n\\n                        for split, split_result in pipeline_result.items():\\n                            print(f\"  {split}:\")\\n                            if isinstance(split_result, dict):  # For multiple metrics per fold\\n                                for metric, value in split_result.items():\\n                                    print(f\"    {metric.upper()}:\")\\n                                    if isinstance(value, str):  # Classification reports\\n                                        print(value)\\n                                    else:  # Other metrics (e.g., accuracy, F1-score)\\n                                        print(f\"      Value: {value}\")\\n                            elif isinstance(split_result, str):  # If it\\'s just a string, like a report\\n                                print(split_result)\\n                            else:  # Unexpected format\\n                                print(f\"    Unexpected format: {split_result}\")\\n                        print(\"========================================\")\\n\\n                    except Exception as e:\\n                        print(f\"Error with {scaler}, {encoder}, {model_name}, {cv_method}: {e}\") #, {balance_method}\\n '"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" X = train.drop('Claim Injury Type', axis=1)\n",
    "y = train['Claim Injury Type']\n",
    "\n",
    "# Define configurations\n",
    "cv_methods = [None] #, KFold(n_splits=10), RepeatedKFold(n_splits=6, n_repeats=2), StratifiedKFold(n_splits=10)\n",
    "scalers = [StandardScaler()] #, MinMaxScaler()\n",
    "encoders = [OneHotEncoder(sparse_output=False, drop=\"first\", handle_unknown='ignore')] # , OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "#balance_methods = ['oversample', 'undersample', 'smote']\n",
    "models = [\n",
    "    (\"DecisionTree\", DecisionTreeClassifier()),\n",
    "    (\"LogisticRegression\", LogisticRegression(class_weight='balanced', max_iter=1000)),\n",
    "    (\"Lasso\", LassoCV())\n",
    "]\n",
    "\n",
    "# Results storage\n",
    "results = []\n",
    "\n",
    "# Iterate through combinations\n",
    "for scaler in scalers:\n",
    "    for encoder in encoders:\n",
    "        for model_name, model in models:\n",
    "            for cv_method in cv_methods:\n",
    "                #for balance_method in balance_methods:\n",
    "                    if model_name in [\"LogisticRegression\", \"Lasso\"] and isinstance(encoder, OrdinalEncoder):\n",
    "                        continue  # Skip OrdinalEncoder for LogisticRegression and Lasso\n",
    "                    # if model_name == \"LogisticRegression\":\n",
    "                    #     balance_method = None  # LogisticRegression does not need balancing\n",
    "                    \n",
    "                    # Apply pipeline steps (e.g., split, scale, encode, model)\n",
    "                    try:\n",
    "                        pipeline_result = pipeline(X, y, cv_method, scaler, encoder, LabelEncoder(), model) #, balance_method\n",
    "                        results.append({\n",
    "                            \"scaler\": scaler.__class__.__name__,\n",
    "                            \"encoder\": encoder.__class__.__name__,\n",
    "                            \"model\": model_name,\n",
    "                            \"cv_method\": \"TrainTestSplit\" if cv_method is None else cv_method.__class__.__name__,\n",
    "                            #\"balance_method\": balance_method if balance_method else 'none',\n",
    "                            \"results\": pipeline_result\n",
    "                        })\n",
    "                        print(\"========================================\")\n",
    "                        print(f\"Scaler: {scaler.__class__.__name__}\")\n",
    "                        print(f\"Encoder: {encoder.__class__.__name__}\")\n",
    "                        print(f\"Model: {model_name}\")\n",
    "                        print(f\"Cross-Validation Method: {'TrainTestSplit' if cv_method is None else cv_method.__class__.__name__}\")\n",
    "                        #print(f\"Balancing Method: {balance_method if balance_method else 'none'}\")\n",
    "                        print(\"Results:\")\n",
    "\n",
    "                        for split, split_result in pipeline_result.items():\n",
    "                            print(f\"  {split}:\")\n",
    "                            if isinstance(split_result, dict):  # For multiple metrics per fold\n",
    "                                for metric, value in split_result.items():\n",
    "                                    print(f\"    {metric.upper()}:\")\n",
    "                                    if isinstance(value, str):  # Classification reports\n",
    "                                        print(value)\n",
    "                                    else:  # Other metrics (e.g., accuracy, F1-score)\n",
    "                                        print(f\"      Value: {value}\")\n",
    "                            elif isinstance(split_result, str):  # If it's just a string, like a report\n",
    "                                print(split_result)\n",
    "                            else:  # Unexpected format\n",
    "                                print(f\"    Unexpected format: {split_result}\")\n",
    "                        print(\"========================================\")\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error with {scaler}, {encoder}, {model_name}, {cv_method}: {e}\") #, {balance_method}\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_split = None\n",
    "kf = KFold(n_splits=10) #if the splits are too many, poor efficiency\n",
    "rkf = RepeatedKFold(n_splits=6, n_repeats=2)  \n",
    "#loo = LeaveOneOut() not good due the size of the dataset\n",
    "skf = StratifiedKFold(n_splits=10)  #good for imbalanced datasets\n",
    "\n",
    "min_max = MinMaxScaler()\n",
    "min_max2 = MinMaxScaler(feature_range=(-1, 1))\n",
    "standard = StandardScaler()\n",
    "robust = RobustScaler()\n",
    "\n",
    "oneHot = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
    "ordinal = OrdinalEncoder()\n",
    "label = LabelEncoder()\n",
    "\n",
    "dt = DecisionTreeClassifier()#0.99/0.39 not use StratifiedKFold\n",
    "#svc = SVC() to expensive for the dataset\n",
    "lasso = LassoCV() #0.74/0.41\n",
    "log_reg = LogisticRegression() #0.78/0.37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para combinar GaussianNB e CategoricalNB\n",
    "def hybrid_naive_bayes(X_num_train, X_cat_train, y_train, X_num_test, X_cat_test):\n",
    "    # Treinar GaussianNB para dados numéricos\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_num_train, y_train)\n",
    "    \n",
    "    # Treinar CategoricalNB para dados categóricos\n",
    "    cnb = CategoricalNB()\n",
    "    cnb.fit(X_cat_train, y_train)\n",
    "\n",
    "    # Predizer probabilidades com ambos os modelos\n",
    "    prob_gnb = gnb.predict_proba(X_num_test)\n",
    "    prob_cnb = cnb.predict_proba(X_cat_test)\n",
    "\n",
    "    # Combinar probabilidades multiplicando-as (assumindo independência)\n",
    "    combined_prob = prob_gnb * prob_cnb\n",
    "\n",
    "    # Retornar a classe com maior probabilidade combinada\n",
    "    return np.argmax(combined_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.51      0.57      2461\n",
      "           1       0.85      0.98      0.91     58173\n",
      "           2       0.47      0.05      0.08     13850\n",
      "           3       0.72      0.91      0.80     29795\n",
      "           4       0.67      0.43      0.53      9579\n",
      "           5       0.17      0.00      0.00       835\n",
      "           6       0.00      0.00      0.00        16\n",
      "           7       0.43      0.10      0.17        96\n",
      "\n",
      "    accuracy                           0.79    114805\n",
      "   macro avg       0.49      0.37      0.38    114805\n",
      "weighted avg       0.74      0.79      0.74    114805\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.47      0.54      2461\n",
      "           1       0.85      0.97      0.91     58173\n",
      "           2       0.34      0.11      0.16     13850\n",
      "           3       0.76      0.83      0.79     29795\n",
      "           4       0.59      0.60      0.60      9579\n",
      "           5       0.10      0.04      0.06       835\n",
      "           6       0.00      0.00      0.00        16\n",
      "           7       0.30      0.10      0.16        96\n",
      "\n",
      "    accuracy                           0.78    114805\n",
      "   macro avg       0.45      0.39      0.40    114805\n",
      "weighted avg       0.73      0.78      0.75    114805\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.45      0.54      2461\n",
      "           1       0.85      0.98      0.91     58173\n",
      "           2       0.41      0.08      0.14     13850\n",
      "           3       0.76      0.85      0.80     29795\n",
      "           4       0.61      0.60      0.61      9579\n",
      "           5       0.13      0.02      0.04       835\n",
      "           6       0.00      0.00      0.00        16\n",
      "           7       0.33      0.11      0.17        96\n",
      "\n",
      "    accuracy                           0.79    114805\n",
      "   macro avg       0.47      0.39      0.40    114805\n",
      "weighted avg       0.74      0.79      0.75    114805\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.46      0.53      2461\n",
      "           1       0.85      0.95      0.90     58173\n",
      "           2       0.32      0.14      0.19     13850\n",
      "           3       0.76      0.83      0.79     29795\n",
      "           4       0.61      0.59      0.60      9579\n",
      "           5       0.09      0.01      0.02       835\n",
      "           6       0.00      0.00      0.00        16\n",
      "           7       0.42      0.10      0.17        96\n",
      "\n",
      "    accuracy                           0.77    114805\n",
      "   macro avg       0.46      0.39      0.40    114805\n",
      "weighted avg       0.73      0.77      0.75    114805\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.45      0.54      2461\n",
      "           1       0.85      0.96      0.90     58173\n",
      "           2       0.36      0.12      0.18     13850\n",
      "           3       0.75      0.85      0.80     29795\n",
      "           4       0.62      0.59      0.61      9579\n",
      "           5       0.00      0.00      0.00       835\n",
      "           6       0.00      0.00      0.00        16\n",
      "           7       0.48      0.10      0.17        96\n",
      "\n",
      "    accuracy                           0.78    114805\n",
      "   macro avg       0.47      0.39      0.40    114805\n",
      "weighted avg       0.74      0.78      0.75    114805\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.44      0.54      2461\n",
      "           1       0.85      0.98      0.91     58173\n",
      "           2       0.41      0.08      0.14     13850\n",
      "           3       0.75      0.88      0.81     29795\n",
      "           4       0.64      0.57      0.60      9579\n",
      "           5       0.00      0.00      0.00       835\n",
      "           6       0.00      0.00      0.00        16\n",
      "           7       1.00      0.01      0.02        96\n",
      "\n",
      "    accuracy                           0.79    114805\n",
      "   macro avg       0.55      0.37      0.38    114805\n",
      "weighted avg       0.74      0.79      0.75    114805\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.41      0.52      2461\n",
      "           1       0.85      0.98      0.91     58173\n",
      "           2       0.43      0.07      0.12     13850\n",
      "           3       0.75      0.88      0.81     29795\n",
      "           4       0.63      0.59      0.61      9579\n",
      "           5       0.00      0.00      0.00       835\n",
      "           6       0.00      0.00      0.00        16\n",
      "           7       1.00      0.01      0.02        96\n",
      "\n",
      "    accuracy                           0.79    114805\n",
      "   macro avg       0.55      0.37      0.37    114805\n",
      "weighted avg       0.74      0.79      0.75    114805\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' # For Naive Bayes\\n# Realizar predição usando o modelo híbrido\\npredictions = hybrid_naive_bayes(\\n    X_train_full_num_scaled, X_train_full_cat_encoded, y_train_full_encoded,\\n    X_test_full_num_scaled, X_test_full_cat_encoded\\n)\\n\\n# Função para avaliar o modelo\\ndef evaluate_model_nb(y_true, y_pred, is_classification=True):\\n    if is_classification:\\n        return classification_report(y_true, y_pred)\\n    else:\\n        mse = mean_squared_error(y_true, y_pred)\\n        r2 = r2_score(y_true, y_pred)\\n        return {\\n            \\'mean_squared_error\\': mse,\\n            \\'r2_score\\': r2\\n        }\\n\\n# Avaliar o modelo (assumindo que \"evaluate_model\" retorna métricas relevantes)\\nresults = evaluate_model_nb(y_test_full_encoded, predictions)\\nprint(results) '"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop('Claim Injury Type', axis=1)\n",
    "y = train['Claim Injury Type']\n",
    "\n",
    "# Perform PCA once on the entire training data\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_full_num = X_train_full.select_dtypes(include=np.number)\n",
    "X_test_full_num = X_test_full.select_dtypes(include=np.number)\n",
    "X_train_full_cat = X_train_full.select_dtypes(exclude=np.number)\n",
    "X_test_full_cat = X_test_full.select_dtypes(exclude=np.number)\n",
    "    \n",
    "# Preprocess the full training data\n",
    "X_train_full_num, X_test_full_num, X_train_full_cat, X_test_full_cat = imputing(X_train_full_num, X_test_full_num, X_train_full_cat, X_test_full_cat)\n",
    "X_train_full_num = to_int(X_train_full_num)\n",
    "X_test_full_num = to_int(X_test_full_num)\n",
    "X_train_full_num_scaled, X_test_full_num_scaled = scaling(X_train_full_num, X_test_full_num, StandardScaler())\n",
    "X_train_full_cat = reduce_cardinality(X_train_full_cat)\n",
    "X_test_full_cat = reduce_cardinality(X_test_full_cat)\n",
    "X_train_full_cat_encoded, X_test_full_cat_encoded = encoding_independent(X_train_full_cat, X_test_full_cat, OneHotEncoder(sparse_output=False, drop=\"first\", handle_unknown='ignore'))\n",
    "y_train_full_encoded, y_test_full_encoded = encoding_dependent(y_train_full, y_test_full, LabelEncoder())\n",
    "X_train_full = pd.concat([X_train_full_num_scaled, X_train_full_cat_encoded], axis=1)\n",
    "X_test_full = pd.concat([X_test_full_num_scaled, X_test_full_cat_encoded], axis=1)\n",
    "\n",
    "\"\"\" # Perform PCA\n",
    "pca = PCA()\n",
    "pca_feat = pca.fit_transform(X_train_full)\n",
    "\n",
    "# Get PCA output as table\n",
    "explained_variance = pca.explained_variance_\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Combine into a dataframe\n",
    "pca_results = pd.DataFrame(\n",
    "    {\n",
    "        \"Eigenvalue\": explained_variance,\n",
    "        \"Difference\": np.insert(np.diff(explained_variance), 0, 0),\n",
    "        \"Proportion\": explained_variance_ratio,\n",
    "        \"Cumulative\": cumulative_explained_variance_ratio\n",
    "    },\n",
    "    index=range(1, pca.n_components_ + 1)\n",
    ")\n",
    "\n",
    "print(pca_results)\n",
    "\n",
    "# figure and axes\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(200, 10))\n",
    "\n",
    "# draw plots\n",
    "\n",
    "ax1.plot(explained_variance, # PLOT THE EIGENVALUES (EXPLAINED VARIANCE)\n",
    "        marker=\".\", markersize=12)\n",
    "\n",
    "ax2.plot(explained_variance_ratio,  # PLOT THE EXPLAINED VARIANCE RATIO\n",
    "        marker=\".\", markersize=12, label=\"Proportion\")\n",
    "\n",
    "ax2.plot(cumulative_explained_variance_ratio,  # PLOT THE CUMULATIVE EXPLAINED VARIANCE RATIO\n",
    "        marker=\".\", markersize=12, linestyle=\"--\", label=\"Cumulative\")\n",
    "\n",
    "# customizations\n",
    "ax2.legend()\n",
    "ax1.set_title(\"Scree Plot\", fontsize=14)\n",
    "ax2.set_title(\"Variance Explained\", fontsize=14)\n",
    "ax1.set_ylabel(\"Eigenvalue\")\n",
    "ax2.set_ylabel(\"Proportion\")\n",
    "ax1.set_xlabel(\"Components\")\n",
    "ax2.set_xlabel(\"Components\")\n",
    "ax1.set_xticks(range(0, pca.n_components_, 2))\n",
    "ax1.set_xticklabels(range(1, pca.n_components_ + 1, 2))\n",
    "ax2.set_xticks(range(0, pca.n_components_, 2))\n",
    "ax2.set_xticklabels(range(1, pca.n_components_ + 1, 2))\n",
    "\n",
    "plt.show() \"\"\"\n",
    "\n",
    "#choosing a pca with 30 components\n",
    "\n",
    "X_train_pca, X_test_pca, pca_feat_names = apply_pca(X_train_full, X_test_full, n_components=30)\n",
    "features = X_train_full.columns.tolist()\n",
    "\n",
    "loadings = pd.DataFrame(\n",
    "    np.dot(X_train_full.T, X_train_pca) / len(X_train_full),\n",
    "    index=features,\n",
    "    columns=pca_feat_names\n",
    ")\n",
    "\n",
    "def _color_red_or_green(val):\n",
    "        if val < -0.45:\n",
    "                color = 'background-color: #ffbdbd'\n",
    "        elif val > 0.45:\n",
    "                color = 'background-color: #b3ffcc'\n",
    "        else:\n",
    "                color = ''\n",
    "        return color\n",
    "\n",
    "# Interpreting each Principal Component\n",
    "styled_loadings = loadings.style.applymap(_color_red_or_green)\n",
    "\n",
    "# Display the styled loadings\n",
    "#display(styled_loadings)\n",
    "\n",
    "# Remove PCA components 14 to 29\n",
    "components_to_remove = [f'PC{i}' for i in range(14, 30)]\n",
    "X_train_pca.drop(columns=components_to_remove, inplace=True)\n",
    "X_test_pca.drop(columns=components_to_remove, inplace=True)\n",
    "pca_feat_names = [f'PC{i}' for i in range(1, 14)]  # Update pca_feat_names to reflect the remaining components\n",
    "\n",
    "model = run_model(X_train_full, y_train_full_encoded, DecisionTreeClassifier(max_depth = 10))\n",
    "model2 = run_model(X_train_full, y_train_full_encoded, DecisionTreeClassifier(max_depth = 20))\n",
    "model3 = run_model(X_train_full, y_train_full_encoded, DecisionTreeClassifier(max_depth = 15))\n",
    "model4 = run_model(X_train_full, y_train_full_encoded, DecisionTreeClassifier(min_samples_split = 100))\n",
    "model5 = run_model(X_train_full, y_train_full_encoded, DecisionTreeClassifier(min_samples_split = 200)) \n",
    "model6 = run_model(X_train_full, y_train_full_encoded, DecisionTreeClassifier(min_samples_split = 500))\n",
    "model7 = run_model(X_train_full, y_train_full_encoded, DecisionTreeClassifier(min_samples_split = 700))\n",
    "#model_pca = run_model(X_train_pca, y_train_full_encoded, DecisionTreeClassifier(criterion = 'entropy'))\n",
    "\n",
    "#is_classification = not isinstance(model, LassoCV)\n",
    "        \n",
    "results = evaluate_model(X_test_full, y_test_full_encoded, model)\n",
    "results2 = evaluate_model(X_test_full, y_test_full_encoded, model2)\n",
    "results3 = evaluate_model(X_test_full, y_test_full_encoded, model3)\n",
    "results4 = evaluate_model(X_test_full, y_test_full_encoded, model4)\n",
    "results5 = evaluate_model(X_test_full, y_test_full_encoded, model5)\n",
    "results6 = evaluate_model(X_test_full, y_test_full_encoded, model6)\n",
    "results7 = evaluate_model(X_test_full, y_test_full_encoded, model7)\n",
    "#results_pca = evaluate_model(X_test_pca, y_test_full_encoded, model_pca)\n",
    "print(results, results2, results3, results4, results5, results6, results7) #, results_pca\n",
    "#print(results_pca)\n",
    "\n",
    "\n",
    "\"\"\" # For Naive Bayes\n",
    "# Realizar predição usando o modelo híbrido\n",
    "predictions = hybrid_naive_bayes(\n",
    "    X_train_full_num_scaled, X_train_full_cat_encoded, y_train_full_encoded,\n",
    "    X_test_full_num_scaled, X_test_full_cat_encoded\n",
    ")\n",
    "\n",
    "# Função para avaliar o modelo\n",
    "def evaluate_model_nb(y_true, y_pred, is_classification=True):\n",
    "    if is_classification:\n",
    "        return classification_report(y_true, y_pred)\n",
    "    else:\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        return {\n",
    "            'mean_squared_error': mse,\n",
    "            'r2_score': r2\n",
    "        }\n",
    "\n",
    "# Avaliar o modelo (assumindo que \"evaluate_model\" retorna métricas relevantes)\n",
    "results = evaluate_model_nb(y_test_full_encoded, predictions)\n",
    "print(results) \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" print('Naive Bayes') #0.37/0.32\\ncnb = CategoricalNB(alpha= 0.1)\\ngnb = GaussianNB(var_smoothing=1e-7)\\nmodel_cat = run_model(X_train_cat_encoded, y_train_encoded, cnb)\\nmodel_num = run_model(X_train_num_scaled, y_train_encoded, gnb)\\n# Obter probabilidades de previsão\\nprob_cat_train = model_cat.predict_proba(X_train_cat_encoded)\\nprob_num_train = model_num.predict_proba(X_train_num_scaled)\\nprob_cat_test = model_cat.predict_proba(X_test_cat_encoded)\\nprob_num_test = model_num.predict_proba(X_test_num_scaled)\\n# Combinar probabilidades (média)\\nprob_combined_train = (prob_cat_train + prob_num_train) / 2\\nprob_combined_test = (prob_cat_test + prob_num_test) / 2\\n#prob_combined_train = (0.7 * prob_cat_train + 0.3 * prob_num_train)\\n#prob_combined_test = (0.7 * prob_cat_test + 0.3 * prob_num_test)\\n# Predizer classe final\\ny_pred_combined_train = np.argmax(prob_combined_train, axis=1)\\ny_pred_combined_test = np.argmax(prob_combined_test, axis=1)\\n# Avaliar o modelo combinado\\nprint('Train:', f1_score(y_train_encoded, y_pred_combined_train, average='macro'))# y_test_num ou y_test_cat são os mesmos\\nprint('Test:', f1_score(y_test_encoded, y_pred_combined_test, average='macro')) \""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" print('Naive Bayes') #0.37/0.32\n",
    "cnb = CategoricalNB(alpha= 0.1)\n",
    "gnb = GaussianNB(var_smoothing=1e-7)\n",
    "model_cat = run_model(X_train_cat_encoded, y_train_encoded, cnb)\n",
    "model_num = run_model(X_train_num_scaled, y_train_encoded, gnb)\n",
    "# Obter probabilidades de previsão\n",
    "prob_cat_train = model_cat.predict_proba(X_train_cat_encoded)\n",
    "prob_num_train = model_num.predict_proba(X_train_num_scaled)\n",
    "prob_cat_test = model_cat.predict_proba(X_test_cat_encoded)\n",
    "prob_num_test = model_num.predict_proba(X_test_num_scaled)\n",
    "# Combinar probabilidades (média)\n",
    "prob_combined_train = (prob_cat_train + prob_num_train) / 2\n",
    "prob_combined_test = (prob_cat_test + prob_num_test) / 2\n",
    "#prob_combined_train = (0.7 * prob_cat_train + 0.3 * prob_num_train)\n",
    "#prob_combined_test = (0.7 * prob_cat_test + 0.3 * prob_num_test)\n",
    "# Predizer classe final\n",
    "y_pred_combined_train = np.argmax(prob_combined_train, axis=1)\n",
    "y_pred_combined_test = np.argmax(prob_combined_test, axis=1)\n",
    "# Avaliar o modelo combinado\n",
    "print('Train:', f1_score(y_train_encoded, y_pred_combined_train, average='macro'))# y_test_num ou y_test_cat são os mesmos\n",
    "print('Test:', f1_score(y_test_encoded, y_pred_combined_test, average='macro')) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age at Injury</th>\n",
       "      <th>Alternative Dispute Resolution</th>\n",
       "      <th>Attorney/Representative</th>\n",
       "      <th>Average Weekly Wage</th>\n",
       "      <th>Birth Year</th>\n",
       "      <th>Carrier Type</th>\n",
       "      <th>County of Injury</th>\n",
       "      <th>COVID-19 Indicator</th>\n",
       "      <th>District Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>IME-4 Count</th>\n",
       "      <th>Industry Code</th>\n",
       "      <th>Industry Code Description</th>\n",
       "      <th>Medical Fee Region</th>\n",
       "      <th>WCIO Cause of Injury Code</th>\n",
       "      <th>WCIO Cause of Injury Description</th>\n",
       "      <th>WCIO Nature of Injury Code</th>\n",
       "      <th>WCIO Nature of Injury Description</th>\n",
       "      <th>WCIO Part Of Body Code</th>\n",
       "      <th>WCIO Part Of Body Description</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Accident Date_Year</th>\n",
       "      <th>Accident Date_Month</th>\n",
       "      <th>Accident Date_Day</th>\n",
       "      <th>Assembly Date_Year</th>\n",
       "      <th>Assembly Date_Month</th>\n",
       "      <th>Assembly Date_Day</th>\n",
       "      <th>C-2 Date_Year</th>\n",
       "      <th>C-2 Date_Month</th>\n",
       "      <th>C-2 Date_Day</th>\n",
       "      <th>C-3 Date_Year</th>\n",
       "      <th>C-3 Date_Month</th>\n",
       "      <th>C-3 Date_Day</th>\n",
       "      <th>First Hearing Date_Year</th>\n",
       "      <th>First Hearing Date_Month</th>\n",
       "      <th>First Hearing Date_Day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claim Identifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6165911</th>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>1A. PRIVATE</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>N</td>\n",
       "      <td>NYC</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>TRANSPORTATION AND WAREHOUSING</td>\n",
       "      <td>IV</td>\n",
       "      <td>31.0</td>\n",
       "      <td>FALL, SLIP OR TRIP, NOC</td>\n",
       "      <td>10.0</td>\n",
       "      <td>CONTUSION</td>\n",
       "      <td>54.0</td>\n",
       "      <td>LOWER LEG</td>\n",
       "      <td>NY Resident</td>\n",
       "      <td>1</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6166141</th>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>1A. PRIVATE</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>N</td>\n",
       "      <td>NYC</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>RETAIL TRADE</td>\n",
       "      <td>IV</td>\n",
       "      <td>75.0</td>\n",
       "      <td>FALLING OR FLYING OBJECT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>CONTUSION</td>\n",
       "      <td>10.0</td>\n",
       "      <td>MULTIPLE HEAD INJURY</td>\n",
       "      <td>NY Resident</td>\n",
       "      <td>1</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165907</th>\n",
       "      <td>59</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>1A. PRIVATE</td>\n",
       "      <td>WESTCHESTER</td>\n",
       "      <td>N</td>\n",
       "      <td>NYC</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>ADMINISTRATIVE AND SUPPORT AND WASTE MANAGEMEN...</td>\n",
       "      <td>III</td>\n",
       "      <td>68.0</td>\n",
       "      <td>STATIONARY OBJECT</td>\n",
       "      <td>49.0</td>\n",
       "      <td>SPRAIN OR TEAR</td>\n",
       "      <td>62.0</td>\n",
       "      <td>BUTTOCKS</td>\n",
       "      <td>NY Resident</td>\n",
       "      <td>0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6166047</th>\n",
       "      <td>55</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1A. PRIVATE</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>N</td>\n",
       "      <td>NYC</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>TRANSPORTATION AND WAREHOUSING</td>\n",
       "      <td>IV</td>\n",
       "      <td>25.0</td>\n",
       "      <td>FROM DIFFERENT LEVEL (ELEVATION)</td>\n",
       "      <td>10.0</td>\n",
       "      <td>CONTUSION</td>\n",
       "      <td>53.0</td>\n",
       "      <td>KNEE</td>\n",
       "      <td>NY Resident</td>\n",
       "      <td>6</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6166102</th>\n",
       "      <td>25</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>1A. PRIVATE</td>\n",
       "      <td>KINGS</td>\n",
       "      <td>N</td>\n",
       "      <td>NYC</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>MANAGEMENT OF COMPANIES AND ENTERPRISES</td>\n",
       "      <td>IV</td>\n",
       "      <td>79.0</td>\n",
       "      <td>OBJECT BEING LIFTED OR HANDLED</td>\n",
       "      <td>40.0</td>\n",
       "      <td>LACERATION</td>\n",
       "      <td>37.0</td>\n",
       "      <td>THUMB</td>\n",
       "      <td>NY Resident</td>\n",
       "      <td>5</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553137</th>\n",
       "      <td>52</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>2A. SIF</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>N</td>\n",
       "      <td>SYRACUSE</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY Resident</td>\n",
       "      <td>5</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553119</th>\n",
       "      <td>59</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>3A. SELF PUBLIC</td>\n",
       "      <td>SUFFOLK</td>\n",
       "      <td>N</td>\n",
       "      <td>HAUPPAUGE</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY Resident</td>\n",
       "      <td>1</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553542</th>\n",
       "      <td>45</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>2A. SIF</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>N</td>\n",
       "      <td>NYC</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY Resident</td>\n",
       "      <td>5</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553455</th>\n",
       "      <td>42</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>4A. SELF PRIVATE</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>N</td>\n",
       "      <td>NYC</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY Resident</td>\n",
       "      <td>5</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553594</th>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3A. SELF PUBLIC</td>\n",
       "      <td>RICHMOND</td>\n",
       "      <td>N</td>\n",
       "      <td>NYC</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY Resident</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>387975 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Age at Injury Alternative Dispute Resolution  \\\n",
       "Claim Identifier                                                 \n",
       "6165911                      19                              N   \n",
       "6166141                      19                              N   \n",
       "6165907                      59                              N   \n",
       "6166047                      55                              N   \n",
       "6166102                      25                              N   \n",
       "...                         ...                            ...   \n",
       "6553137                      52                              N   \n",
       "6553119                      59                              N   \n",
       "6553542                      45                              N   \n",
       "6553455                      42                              N   \n",
       "6553594                       0                              N   \n",
       "\n",
       "                 Attorney/Representative  Average Weekly Wage  Birth Year  \\\n",
       "Claim Identifier                                                            \n",
       "6165911                                N                  NaN      2003.0   \n",
       "6166141                                N                  NaN      2003.0   \n",
       "6165907                                N                  0.0      1963.0   \n",
       "6166047                                N                  0.0         0.0   \n",
       "6166102                                N                  0.0      1997.0   \n",
       "...                                  ...                  ...         ...   \n",
       "6553137                                N                  NaN      1960.0   \n",
       "6553119                                Y                  0.0      1965.0   \n",
       "6553542                                Y                  0.0      1979.0   \n",
       "6553455                                Y                  0.0      1981.0   \n",
       "6553594                                Y                  0.0         NaN   \n",
       "\n",
       "                      Carrier Type County of Injury COVID-19 Indicator  \\\n",
       "Claim Identifier                                                         \n",
       "6165911                1A. PRIVATE            BRONX                  N   \n",
       "6166141                1A. PRIVATE           QUEENS                  N   \n",
       "6165907                1A. PRIVATE      WESTCHESTER                  N   \n",
       "6166047                1A. PRIVATE           QUEENS                  N   \n",
       "6166102                1A. PRIVATE            KINGS                  N   \n",
       "...                            ...              ...                ...   \n",
       "6553137                    2A. SIF        JEFFERSON                  N   \n",
       "6553119            3A. SELF PUBLIC          SUFFOLK                  N   \n",
       "6553542                    2A. SIF           QUEENS                  N   \n",
       "6553455           4A. SELF PRIVATE           QUEENS                  N   \n",
       "6553594            3A. SELF PUBLIC         RICHMOND                  N   \n",
       "\n",
       "                 District Name Gender  IME-4 Count  Industry Code  \\\n",
       "Claim Identifier                                                    \n",
       "6165911                    NYC      M          NaN           48.0   \n",
       "6166141                    NYC      F          NaN           45.0   \n",
       "6165907                    NYC      F          NaN           56.0   \n",
       "6166047                    NYC      F          NaN           48.0   \n",
       "6166102                    NYC      M          NaN           55.0   \n",
       "...                        ...    ...          ...            ...   \n",
       "6553137               SYRACUSE      M          NaN            NaN   \n",
       "6553119              HAUPPAUGE      F          NaN            NaN   \n",
       "6553542                    NYC      M          NaN            NaN   \n",
       "6553455                    NYC      M          NaN            NaN   \n",
       "6553594                    NYC      M          NaN            NaN   \n",
       "\n",
       "                                          Industry Code Description  \\\n",
       "Claim Identifier                                                      \n",
       "6165911                              TRANSPORTATION AND WAREHOUSING   \n",
       "6166141                                                RETAIL TRADE   \n",
       "6165907           ADMINISTRATIVE AND SUPPORT AND WASTE MANAGEMEN...   \n",
       "6166047                              TRANSPORTATION AND WAREHOUSING   \n",
       "6166102                     MANAGEMENT OF COMPANIES AND ENTERPRISES   \n",
       "...                                                             ...   \n",
       "6553137                                                         NaN   \n",
       "6553119                                                         NaN   \n",
       "6553542                                                         NaN   \n",
       "6553455                                                         NaN   \n",
       "6553594                                                         NaN   \n",
       "\n",
       "                 Medical Fee Region  WCIO Cause of Injury Code  \\\n",
       "Claim Identifier                                                 \n",
       "6165911                          IV                       31.0   \n",
       "6166141                          IV                       75.0   \n",
       "6165907                         III                       68.0   \n",
       "6166047                          IV                       25.0   \n",
       "6166102                          IV                       79.0   \n",
       "...                             ...                        ...   \n",
       "6553137                           I                        NaN   \n",
       "6553119                          IV                        NaN   \n",
       "6553542                          IV                        NaN   \n",
       "6553455                          IV                        NaN   \n",
       "6553594                          IV                        NaN   \n",
       "\n",
       "                  WCIO Cause of Injury Description  \\\n",
       "Claim Identifier                                     \n",
       "6165911                    FALL, SLIP OR TRIP, NOC   \n",
       "6166141                   FALLING OR FLYING OBJECT   \n",
       "6165907                          STATIONARY OBJECT   \n",
       "6166047           FROM DIFFERENT LEVEL (ELEVATION)   \n",
       "6166102             OBJECT BEING LIFTED OR HANDLED   \n",
       "...                                            ...   \n",
       "6553137                                        NaN   \n",
       "6553119                                        NaN   \n",
       "6553542                                        NaN   \n",
       "6553455                                        NaN   \n",
       "6553594                                        NaN   \n",
       "\n",
       "                  WCIO Nature of Injury Code  \\\n",
       "Claim Identifier                               \n",
       "6165911                                 10.0   \n",
       "6166141                                 10.0   \n",
       "6165907                                 49.0   \n",
       "6166047                                 10.0   \n",
       "6166102                                 40.0   \n",
       "...                                      ...   \n",
       "6553137                                  NaN   \n",
       "6553119                                  NaN   \n",
       "6553542                                  NaN   \n",
       "6553455                                  NaN   \n",
       "6553594                                  NaN   \n",
       "\n",
       "                 WCIO Nature of Injury Description  WCIO Part Of Body Code  \\\n",
       "Claim Identifier                                                             \n",
       "6165911                                  CONTUSION                    54.0   \n",
       "6166141                                  CONTUSION                    10.0   \n",
       "6165907                             SPRAIN OR TEAR                    62.0   \n",
       "6166047                                  CONTUSION                    53.0   \n",
       "6166102                                 LACERATION                    37.0   \n",
       "...                                            ...                     ...   \n",
       "6553137                                        NaN                     NaN   \n",
       "6553119                                        NaN                     NaN   \n",
       "6553542                                        NaN                     NaN   \n",
       "6553455                                        NaN                     NaN   \n",
       "6553594                                        NaN                     NaN   \n",
       "\n",
       "                 WCIO Part Of Body Description     Zip Code  \\\n",
       "Claim Identifier                                              \n",
       "6165911                              LOWER LEG  NY Resident   \n",
       "6166141                   MULTIPLE HEAD INJURY  NY Resident   \n",
       "6165907                               BUTTOCKS  NY Resident   \n",
       "6166047                                   KNEE  NY Resident   \n",
       "6166102                                  THUMB  NY Resident   \n",
       "...                                        ...          ...   \n",
       "6553137                                    NaN  NY Resident   \n",
       "6553119                                    NaN  NY Resident   \n",
       "6553542                                    NaN  NY Resident   \n",
       "6553455                                    NaN  NY Resident   \n",
       "6553594                                    NaN  NY Resident   \n",
       "\n",
       "                  Number of Dependents  Accident Date_Year  \\\n",
       "Claim Identifier                                             \n",
       "6165911                              1              2022.0   \n",
       "6166141                              1              2022.0   \n",
       "6165907                              0              2022.0   \n",
       "6166047                              6              2022.0   \n",
       "6166102                              5              2022.0   \n",
       "...                                ...                 ...   \n",
       "6553137                              5              2012.0   \n",
       "6553119                              1              2024.0   \n",
       "6553542                              5              2024.0   \n",
       "6553455                              5              2024.0   \n",
       "6553594                              5                 NaN   \n",
       "\n",
       "                  Accident Date_Month  Accident Date_Day  Assembly Date_Year  \\\n",
       "Claim Identifier                                                               \n",
       "6165911                          12.0               24.0                2023   \n",
       "6166141                          11.0               20.0                2023   \n",
       "6165907                          12.0               26.0                2023   \n",
       "6166047                          12.0               28.0                2023   \n",
       "6166102                          12.0               20.0                2023   \n",
       "...                               ...                ...                 ...   \n",
       "6553137                           9.0               12.0                2024   \n",
       "6553119                           5.0               22.0                2024   \n",
       "6553542                           5.0                6.0                2024   \n",
       "6553455                           2.0               24.0                2024   \n",
       "6553594                           NaN                NaN                2024   \n",
       "\n",
       "                  Assembly Date_Month  Assembly Date_Day  C-2 Date_Year  \\\n",
       "Claim Identifier                                                          \n",
       "6165911                             1                  2         2023.0   \n",
       "6166141                             1                  2         2023.0   \n",
       "6165907                             1                  2         2022.0   \n",
       "6166047                             1                  2         2023.0   \n",
       "6166102                             1                  2         2022.0   \n",
       "...                               ...                ...            ...   \n",
       "6553137                             6                  5         2012.0   \n",
       "6553119                             6                  5            NaN   \n",
       "6553542                             6                  5            NaN   \n",
       "6553455                             6                  5            NaN   \n",
       "6553594                             6                  5            NaN   \n",
       "\n",
       "                  C-2 Date_Month  C-2 Date_Day  C-3 Date_Year  C-3 Date_Month  \\\n",
       "Claim Identifier                                                                \n",
       "6165911                      1.0           2.0            NaN             NaN   \n",
       "6166141                      1.0           2.0            NaN             NaN   \n",
       "6165907                     12.0          31.0            NaN             NaN   \n",
       "6166047                      1.0           2.0            NaN             NaN   \n",
       "6166102                     12.0          31.0            NaN             NaN   \n",
       "...                          ...           ...            ...             ...   \n",
       "6553137                     10.0          23.0            NaN             NaN   \n",
       "6553119                      NaN           NaN         2024.0             5.0   \n",
       "6553542                      NaN           NaN            NaN             NaN   \n",
       "6553455                      NaN           NaN         2024.0             5.0   \n",
       "6553594                      NaN           NaN         2024.0             5.0   \n",
       "\n",
       "                  C-3 Date_Day  First Hearing Date_Year  \\\n",
       "Claim Identifier                                          \n",
       "6165911                    NaN                      NaN   \n",
       "6166141                    NaN                      NaN   \n",
       "6165907                    NaN                      NaN   \n",
       "6166047                    NaN                      NaN   \n",
       "6166102                    NaN                      NaN   \n",
       "...                        ...                      ...   \n",
       "6553137                    NaN                      NaN   \n",
       "6553119                   28.0                      NaN   \n",
       "6553542                    NaN                      NaN   \n",
       "6553455                   21.0                      NaN   \n",
       "6553594                   28.0                      NaN   \n",
       "\n",
       "                  First Hearing Date_Month  First Hearing Date_Day  \n",
       "Claim Identifier                                                    \n",
       "6165911                                NaN                     NaN  \n",
       "6166141                                NaN                     NaN  \n",
       "6165907                                NaN                     NaN  \n",
       "6166047                                NaN                     NaN  \n",
       "6166102                                NaN                     NaN  \n",
       "...                                    ...                     ...  \n",
       "6553137                                NaN                     NaN  \n",
       "6553119                                NaN                     NaN  \n",
       "6553542                                NaN                     NaN  \n",
       "6553455                                NaN                     NaN  \n",
       "6553594                                NaN                     NaN  \n",
       "\n",
       "[387975 rows x 37 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClaim Injury Type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lopes\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\tree\\_classes.py:528\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    506\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m    For a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;124;03m        The predicted classes, or the predict values.\u001b[39;00m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 528\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    529\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[0;32m    530\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32mc:\\Users\\lopes\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\utils\\validation.py:1661\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "test['Claim Injury Type'] = dt.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export test data predictions\n",
    "#test['DrugPlant'].to_csv('Exercise1_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2425",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
