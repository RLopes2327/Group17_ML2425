{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_data.csv')\n",
    "test = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_index('Claim Identifier', inplace=True)\n",
    "train.drop_duplicates(inplace=True)\n",
    "train.drop('OIICS Nature of Injury Description', axis=1, inplace=True)\n",
    "\n",
    "#train.drop(columns=['Birth Year', 'Age at Injury', 'Number of Dependents', 'WCIO Cause of Injury Code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = train.select_dtypes(include=np.number).columns.tolist()\n",
    "train_cat = train.select_dtypes(exclude=np.number).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical columns: Impute with mean\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "train[train_num] = pd.DataFrame(\n",
    "    num_imputer.fit_transform(train[train_num]),\n",
    "    columns=train_num,\n",
    "    index=train.index\n",
    ")\n",
    "\n",
    "# Categorical columns: Impute with most frequent (mode)\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "train[train_cat] = pd.DataFrame(\n",
    "    cat_imputer.fit_transform(train[train_cat]),\n",
    "    columns=train_cat,\n",
    "    index=train.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns='Claim Injury Type')\n",
    "y = train['Claim Injury Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = X.select_dtypes(include=np.number).set_index(X.index)\n",
    "X_cat = X.select_dtypes(exclude=np.number).set_index(X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_num) #fit to training data\n",
    "X_num_scaled = scaler.transform(X_num) # this will return an array\n",
    "X_num_scaled = pd.DataFrame(X_num_scaled, columns = X_num.columns).set_index(X.index) # Convert the array to a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = X_cat.astype(str)\n",
    "\n",
    "enc1 = OrdinalEncoder() #encoder for features\n",
    "enc2 = LabelEncoder() #encoder for labels\n",
    "enc1.fit(X_cat)\n",
    "X_cat_encoded = pd.DataFrame(enc1.transform(X_cat), columns = X_cat.columns).set_index(X.index)\n",
    "y_encoded = enc2.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_num_scaled, X_cat_encoded], axis=1)\n",
    "y = pd.DataFrame(y_encoded, columns=['Claim Injury Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' X_train, X_val, y_train, y_val = train_test_split(X_combined, y_encoded_df, test_size=0.25, stratify = y_encoded_df, random_state=5) '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" X_train, X_val, y_train, y_val = train_test_split(X_combined, y_encoded_df, test_size=0.25, stratify = y_encoded_df, random_state=5) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' model = MLPClassifier().fit(X_train, y_train) '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" model = MLPClassifier().fit(X_train, y_train) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" pred_val = model.predict(X_val)\\nprint('F1 Score:' ,f1_score(y_val, pred_val, average='macro'))\\nprint('Mean Accuracy:' ,model.score(X_val, y_val)) \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" pred_val = model.predict(X_val)\n",
    "print('F1 Score:' ,f1_score(y_val, pred_val, average='macro'))\n",
    "print('Mean Accuracy:' ,model.score(X_val, y_val)) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def avg_score(model):\n",
    "    # apply kfold\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    # create lists to store the results from the different models \n",
    "    score_train = []\n",
    "    score_val = []\n",
    "    timer = []\n",
    "    n_iter = []\n",
    "    \n",
    "    for train_index, val_index in skf.split(X,y):\n",
    "        # get the indexes of the observations assigned for each partition\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        # start counting time\n",
    "        begin = time.perf_counter()\n",
    "        # fit the model to the data\n",
    "        model.fit(X_train, y_train)\n",
    "        # finish counting time\n",
    "        end = time.perf_counter()\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        pred_val = model.predict(X_val)\n",
    "        # check the mean accuracy for the train\n",
    "        value_train = f1_score(y_train, pred_train, average='macro')\n",
    "        # check the mean accuracy for the validation\n",
    "        value_val = f1_score(y_val, pred_val, average='macro')\n",
    "        # append the accuracies, the time and the number of iterations in the corresponding list\n",
    "        score_train.append(value_train)\n",
    "        score_val.append(value_val)\n",
    "        timer.append(end-begin)\n",
    "        n_iter.append(model.n_iter_)\n",
    "    # calculate the average and the std for each measure (accuracy, time and number of iterations)\n",
    "    avg_time = round(np.mean(timer),3)\n",
    "    avg_train = round(np.mean(score_train),3)\n",
    "    avg_val = round(np.mean(score_val),3)\n",
    "    std_time = round(np.std(timer),2)\n",
    "    std_train = round(np.std(score_train),2)\n",
    "    std_val = round(np.std(score_val),2)\n",
    "    avg_iter = round(np.mean(n_iter),1)\n",
    "    std_iter = round(np.std(n_iter),1)\n",
    "    \n",
    "    return str(avg_time) + '+/-' + str(std_time), str(avg_train) + '+/-' + str(std_train),\\\n",
    "str(avg_val) + '+/-' + str(std_val), str(avg_iter) + '+/-' + str(std_iter)\n",
    "\n",
    "def show_results(df, *args):\n",
    "    \"\"\"\n",
    "    Receive an empty dataframe and the different models and call the function avg_score\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    # for each model passed as argument\n",
    "    for arg in args:\n",
    "        # obtain the results provided by avg_score\n",
    "        time, avg_train, avg_val, avg_iter = avg_score(arg)\n",
    "        # store the results in the right row\n",
    "        df.iloc[count] = time, avg_train, avg_val, avg_iter\n",
    "        count+=1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_simple = MLPClassifier(hidden_layer_sizes=(1))\n",
    "#model_medium = MLPClassifier(hidden_layer_sizes=(8))\n",
    "#model_complex = MLPClassifier(hidden_layer_sizes=(100,100,100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Simple</th>\n",
       "      <td>27.591+/-2.28</td>\n",
       "      <td>0.084+/-0.0</td>\n",
       "      <td>0.084+/-0.0</td>\n",
       "      <td>17.1+/-0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Time        Train   Validation  Iterations\n",
       "Simple  27.591+/-2.28  0.084+/-0.0  0.084+/-0.0  17.1+/-0.3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['Time','Train','Validation', 'Iterations'], index = ['Simple'])\n",
    "show_results(df, model_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' model_maxiter_20 = MLPClassifier(max_iter = 20, hidden_layer_sizes=(8)) '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" model_maxiter_20 = MLPClassifier(max_iter = 20, hidden_layer_sizes=(8)) \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
